{"cells":[{"cell_type":"markdown","metadata":{"id":"JkBKubyZ7na7"},"source":["<div style=\"width: 100%; clear: both;\">\n","<div style=\"float: left; width: 50%;\">\n","<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n","</div>\n","</div>\n","<div style=\"float: right; width: 50%;\">\n","<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.977 · Anàlisis de sentiments i textos</p>\n","<p style=\"margin: 0; text-align:right;\">Màster Universitari de Ciencia de Dades(Data science)</p>\n","<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudis d'Informàtica, Multimèdia i Telecomunicacions</p>\n","</div>\n","</div>\n","<div style=\"width: 100%; clear: both;\">\n","<div style=\"width:100%;\">&nbsp;</div>"]},{"cell_type":"markdown","source":["**Pràctica realitzada per: Núria Aguilera i Joaquim Quadrada, 16/06/2023**"],"metadata":{"id":"kf1vdkhGnsdg"}},{"cell_type":"markdown","metadata":{"id":"qjWsCAwv7na-"},"source":["# PRA 3: Deep Learning per a l'anàlisi de textos\n","\n","En aquesta pràctica revisarem i aplicarem els coneixements apresos durant el curs i, en més detall, en els darrers mòduls. En concret tractarem els temes següents:\n","\n","1. **Traducció automàtica**: amb custom embeddings i amb embeddings preentrenats.\n","2. **Classificació de frases**: Aplicació dels conceptes ja treballats per a la reutilització de l'arquitectura de dos models.\n","\n","3. **Detecció de NER i NEL**: detecció i classificació d'entitats nomenades (NER) i entity linking basant-nos en els temes ja treballats als notebooks de NER i NEL i afegint-hi un exemple senzill de transformers.\n","\n","També incloem altres temes transversals treballats al llarg de l'assignatura."]},{"cell_type":"markdown","metadata":{"id":"B3Opj4kn7nbA"},"source":["# PART 1"]},{"cell_type":"markdown","metadata":{"id":"L8DAwGy17nbB"},"source":["En aquesta primera part de la pràctica es demana resoldre els exercicis usant la llibreria **KERAS**."]},{"cell_type":"markdown","metadata":{"id":"kyW13h9Z7nbB"},"source":["# 1. Traducció Automàtica (4 punts)"]},{"cell_type":"markdown","metadata":{"id":"JuKkXmmS7nbD"},"source":["## 1.1 TA amb Custom Embeddings (2 punts)"]},{"cell_type":"markdown","metadata":{"id":"FuhhJrUk7nbD"},"source":["L'objectiu d'aquest apartat és entrenar un model de traducció automàtica entre anglès i holandès, seguint els mateixos passos que al notebook de Machine Translation."]},{"cell_type":"markdown","metadata":{"id":"Pdz0sUSb7nbD"},"source":["<strong>Implementació:</strong> Seguint els passos treballats al notebook de traducció automàtica, implementar i entrenar un model de traducció automàtica, de l'anglès al holandès. <br>\n","    - La capa embedding deu tenir una dimensió igual a 300 <br>\n","    - Es recomana una longitud màxima de seqüència de 12 <br>\n"," <br>\n","\n","Mostreu l'aplicació del model entrenat amb algun exemple."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25085,"status":"ok","timestamp":1687095130628,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"},"user_tz":-120},"id":"ciWxb-V5uCN2","outputId":"1bdeadf2-5345-47bc-c47a-55d8bb241c6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145143,"status":"ok","timestamp":1687095286489,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"},"user_tz":-120},"id":"U4hWr9Rv7nbF","outputId":"50ca9bd2-e500-4db8-cb9f-5ba376cb5930"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting numpy==1.19.5\n","  Downloading numpy-1.19.5.zip (7.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: numpy\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for numpy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for numpy (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n","\u001b[31m  ERROR: Failed building wheel for numpy\u001b[0m\u001b[31m\n","\u001b[0mFailed to build numpy\n","\u001b[31mERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install numpy==1.19.5"]},{"cell_type":"markdown","metadata":{"id":"L28axKt4kIwO"},"source":["Primer haureu de carregar les dades proporcionades, que trobareu al fitxer mt/nld.txt"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":699,"status":"ok","timestamp":1687095434358,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"},"user_tz":-120},"id":"oVYldy9c7nbG","outputId":"0dfd9476-fa29-4d49-f3ea-ef9faec30d1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["[['Go.' 'Lopen!']\n"," ['Go.' 'Vooruit.']\n"," ['Hi.' 'Hoi.']\n"," ...\n"," [\"They don't know each other very well.\"\n","  'Zij kennen elkaar niet zo goed.']\n"," [\"They don't know each other very well.\"\n","  'Ze kennen elkaar niet erg goed.']\n"," ['They enjoyed themselves at the party.'\n","  'Ze hadden het naar hun zin op het feest.']]\n"]}],"source":["#############################################\n","# Carreguem les dades proporcionades del fitxer nld.txt\n","from numpy import array\n","\n","def to_lines(text):\n","    sents = text.strip().split('\\n')\n","    sents = [i.split('\\t')[:2] for i in sents]\n","    return sents\n","\n","try:\n","  file = open('/content/nld.txt', mode='rt', encoding='utf-8')\n","except:\n","  file = open('/content/drive/MyDrive/nld.txt', mode='rt', encoding='utf-8')\n","\n","text = file.read()\n","file.close()\n","\n","eng_dutch = to_lines(text)\n","eng_dutch = array(eng_dutch)\n","\n","eng_dutch = eng_dutch[:60000,:]\n","print(eng_dutch)\n","#############################################\n"]},{"cell_type":"markdown","metadata":{"id":"6fmFddVqkYU_"},"source":["Preprocessar les dades, per eliminar puntuacions i posar en minúscula"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"JgIsoQqS7nbH","executionInfo":{"status":"ok","timestamp":1687095508316,"user_tz":-120,"elapsed":946,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}}},"outputs":[],"source":["#############################################\n","# Preprocesamos los datos, elimina puntuacions i posa en minúscules\n","import string\n","\n","#Per cada idioma treurem les puntuacions\n","eng_dutch[:,0] = [x.translate(str.maketrans('', '', string.punctuation)) for x in eng_dutch[:,0]]\n","eng_dutch[:,1] = [x.translate(str.maketrans('', '', string.punctuation)) for x in eng_dutch[:,1]]\n","\n","# Pasem a minúscules cada idioma\n","for i in range(len(eng_dutch)):\n","    eng_dutch[i,0] = eng_dutch[i,0].lower()\n","    eng_dutch[i,1] = eng_dutch[i,1].lower()\n","#############################################\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XRInE02Skhbv"},"source":["Visualitzar les dades resultants, per tenir una idea de com seran les dades amb què treballarem, en concret veure la mida del corpus tant els vectors de l'anglès com els de l'holandès."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":661},"executionInfo":{"elapsed":1120,"status":"ok","timestamp":1687095512781,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"},"user_tz":-120},"id":"d8LfflHB7nbI","outputId":"3687857a-89e0-436d-a923-a91f24bda40a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mida del corpus general: 60000\n","Mida del corpus de vectors de l'anglès: 60000\n","Mida del corpus de vectors de l'holandès: 60000\n","Exemples de vectors de l'anglès\n","['go' 'go' 'hi' 'hi' 'hi' 'run' 'run' 'run' 'run' 'who' 'wow' 'duck'\n"," 'fire' 'fire' 'help' 'jump' 'stop' 'stop' 'stop' 'stop']\n","Exemples de vectors de l'holandès\n","['lopen' 'vooruit' 'hoi' 'hé' 'hai' 'ren' 'vlucht' 'ren' 'vlucht' 'wie'\n"," 'das niet gek' 'eend' 'vuur' 'brand' 'help' 'spring' 'stop' 'hou op'\n"," 'hou daarmee op' 'geen beweging']\n"]}],"source":["#############################################\n","# SOLUCIÓ                                  #\n","#############################################\n","\n","# Visualitzem les dades\n","import matplotlib.pyplot as plt\n","\n","length_for_eng = list(map(lambda x: len(x), eng_dutch[:,0]))\n","# Creem subgràfic per al primer histograma\n","#plt.hist(length_for_eng)\n","plt.subplot(1, 2, 1)\n","plt.hist(length_for_eng)\n","plt.title('Anglès')\n","plt.xlabel('Text length')\n","plt.ylabel('Frequency')\n","\n","length_for_dutch = list(map(lambda x: len(x), eng_dutch[:,1]))\n","# Creem subgràfic per al segon histograma\n","plt.subplot(1, 2, 2)\n","plt.hist(length_for_dutch)\n","plt.title('Holandés')\n","plt.xlabel('Text length')\n","plt.ylabel('Frequency')\n","\n","# Ajustar els espais entre subgràficos\n","plt.tight_layout()\n","\n","# Mostrar els gràfics\n","plt.show()\n","\n","# Mostrar la mida del corpus\n","print(\"Mida del corpus general:\", len(eng_dutch))\n","# Mostrar els vectors de l'anglès i els de l'holandès\n","print(\"Mida del corpus de vectors de l'anglès:\", len(eng_dutch[:, 0]))\n","print(\"Mida del corpus de vectors de l'holandès:\", len(eng_dutch[:, 1]))\n","print(\"Exemples de vectors de l'anglès\")\n","print(eng_dutch[:20, 0])\n","print(\"Exemples de vectors de l'holandès\")\n","print(eng_dutch[:20, 1])"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3656,"status":"ok","timestamp":1687095524167,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"},"user_tz":-120},"id":"WPv_880u7nbJ","outputId":"944fb174-5814-475d-d0fb-57caf25d1d61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"]}],"source":["!pip install keras"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7620,"status":"ok","timestamp":1687095533565,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"},"user_tz":-120},"id":"isjIX82C7nbK","outputId":"a83c02ee-58b8-43ed-c0fe-7f287901da05"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"markdown","metadata":{"id":"JXqDyZiEks-S"},"source":["Calcular el vocabulari tant en holandès com en anglès, i imprimir-ne la mida."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9118,"status":"ok","timestamp":1687095546861,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"},"user_tz":-120},"id":"3BU-R8cYgj9E","outputId":"f2b8d924-0a91-44d7-b941-c5f09e13e284"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"]}],"source":["!pip install --upgrade keras"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11599,"status":"ok","timestamp":1687095563638,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"},"user_tz":-120},"id":"ofwfcS6f7nbL","outputId":"87027fbb-ca29-43f2-cdf0-830af198b887"},"outputs":[{"output_type":"stream","name":"stdout","text":["English vocabulary size:  8377\n","Dutch vocabulary size:  11753\n"]}],"source":["#############################################\n","# SOLUCIÓ                                  #\n","#############################################\n","# Calcular el vocabulari tant en holandès com en anglès, i imprimir-ne la mida.\n","\n","from keras.preprocessing.text import Tokenizer\n","\n","def tokenization(sentences):\n","    tokenizer = Tokenizer()\n","    tokenizer.fit_on_texts(sentences)\n","    return tokenizer\n","\n","eng_tokenizer = tokenization(eng_dutch[:, 0])\n","# print(eng_tokenizer.word_index.keys())\n","# Obté el diccionari de paraules e index a partir de l'atribut 'word_index' de l'objecte 'Tokenizer'.\n","eng_vocab_size = len(eng_tokenizer.word_index) + 1\n","print('English vocabulary size: ',eng_vocab_size)\n","\n","dutch_tokenizer = tokenization(eng_dutch[:, 1])\n","dutch_vocab_size = len(dutch_tokenizer.word_index) + 1\n","print('Dutch vocabulary size: ', dutch_vocab_size)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fPXEAlbGoSuL"},"source":["Separem els conjunts d'entrenament per idioma i els codifiquem."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4546,"status":"ok","timestamp":1687095572894,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"},"user_tz":-120},"id":"mX7rtG4Q7nbM","outputId":"39b7c586-e410-4bd2-b6fd-236aecae63b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Frases en holandes:\n"," ['hij is een typische japanse man' 'ze was aan het hijgen'\n"," 'tom heeft een briefje in marias kluisje achtergelaten' ...\n"," 'we zaten recht tegenover directieleden' 'jullie moeten meer vezels eten'\n"," 'tom is hier altijd']\n","\n","Frases en holandes codificades:\n"," [[   5 2452  685  257]\n"," [  37   16 4353    0]\n"," [2619   13  342 2948]\n"," ...\n"," [   6  429   43 4248]\n"," [   6   98  121 4107]\n"," [   2    7  139   44]]\n"]}],"source":["#############################################\n","# SOLUCIÓ                                  #\n","#############################################\n","# Importació de biblioteques:\n","from sklearn.model_selection import train_test_split\n","from keras.utils import pad_sequences\n","\n","def encode_sequences(tokenizer, length, lines):\n","    # Converteix les linies de texte en seqüències numériques amb el métode texts_to_sequences\n","    seq = tokenizer.texts_to_sequences(lines)\n","    # Apliquem el faciment de seqüències per asegurar que totes les seqüències son iguals\n","    seq = pad_sequences(seq, maxlen=length, padding='post')\n","    return seq\n","\n","# Dividim les dades en conjunt d'entrenament i proves, en una proporció 80:20 (20% per proves) i establim una llavor per la reproductibilitat\n","train, test = train_test_split(eng_dutch, test_size=0.2, random_state = 12)\n","\n","# Codificació de seqüències de texte per als conjunts d'entrenament i proves\n","# Aplica la funció 'encode_sequences' al tokenitzador 'eng_tokenizer' per obtenir les seqüències codificades per les entrades de entrenament\n","max_text_len = 4     # Longitut de la frase més llarga\n","\n","trainX = encode_sequences(eng_tokenizer, max_text_len, train[:, 0])\n","# Obtenim les seqüències codificades per les sortides d'entrenament.\n","trainY = encode_sequences(dutch_tokenizer, max_text_len, train[:, 1])\n","print('Frases en holandes:\\n', train[:,1])\n","print('\\nFrases en holandes codificades:\\n', trainX)\n","\n","# Codifiquem les seqüències de texte per les entrades i sortides del conjunt de prova.\n","testX = encode_sequences(eng_tokenizer, max_text_len, test[:, 0])\n","testY = encode_sequences(dutch_tokenizer, max_text_len, test[:, 1])\n"]},{"cell_type":"markdown","metadata":{"id":"9fYxSWIwoYSB"},"source":["Definim el model encoder-decoder basant-nos en el notebook vist a l'assignatura, i instànim el model amb una capa d'embedding per a les frases de la llengua origen (anglès) i la dimensió de l'última capa com el vocabulari de la llengua destinació (holandès)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"bGLbPLtE7nbN","executionInfo":{"status":"ok","timestamp":1687095582663,"user_tz":-120,"elapsed":5055,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}}},"outputs":[],"source":["#############################################\n","# Definim el model encoder-decoder\n","# Definim una arquitectura de model de seqüència amb seqüència amb atenció utilitzant capes d'incrustació (embedding) i capes LSTM\n","\n","from keras.models import Sequential     # per crear un model seqüèncial\n","from keras.layers import Dense, LSTM, Embedding, RepeatVector    # per afegir diferents capes al model\n","\n","embed_vec_length = 300   # Longitut del vector embedding, dimensió del vector\n","units = 200      # quantitat d'unitats en la capa LSTM\n","\n","\n","def define_model(eng_vocab_size, embed_vec_len, max_text_len, out_vocab_size):\n","    ed_model = Sequential()    # Crea instància del model seqüencial\n","    # Afegeix una cap d'incrustació que converteix els indexos de paraules en vectors d'incrustació de longitut 'embed_vec_len'.\n","    # L'entrada té la longitut 'max_text_len' i s'extableis mask_zero=Trueper ignorar les entrades de valor zero.\n","    ed_model.add(Embedding(eng_vocab_size, embed_vec_length, input_length = max_text_len, mask_zero=True))\n","    ed_model.add(LSTM(units))      # afegeix una capa LSTM amb 'units' unitats, que procesa la seqüència d'entrada i genera un estat ocult\n","    ed_model.add(RepeatVector(max_text_len))   # Repeteix l'estat ocult 'max_text_len' vegades per generar una seqüència de sortida enlloc d'un unic estat ocult.\n","    ed_model.add(LSTM(units, return_sequences=True))  # Afegeix una altra capa LSTM amb 'units' unitats i indiquem 'return_sequences=True' per obtenir una seqüència de sortida en lloc d'un sol estat ocult.\n","    ed_model.add(Dense(out_vocab_size, activation='softmax'))   # Afegeix una capa 'Dense' amb 'out_vocab_size' neurones i activació 'softmax' per obtenir la distribució de probabilitat sobre el vocabulari de la llengua destí.\n","    return ed_model\n","\n","# Passem a la funció: la mida del vocabulari de la llengua origen, la longitut del vector embedding,\n","# la longituT màxima de les seqüències de texto d'entrada i la mida del vocabulari de la lengua destí.\n","ed_model = define_model(eng_vocab_size, embed_vec_length, max_text_len, dutch_vocab_size)"]},{"cell_type":"markdown","metadata":{"id":"kuufosmqoxcA"},"source":["Compilem el model"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"wNwpJh4D7nbO","executionInfo":{"status":"ok","timestamp":1687095588473,"user_tz":-120,"elapsed":213,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}}},"outputs":[],"source":["#############################################\n","# Compilació d'un model a TensorFlow-Keras utilitzant l'optimitzador RMSprop i la funció de pèrdua \"sparse_categorical_crossentropy\".\n","# Optimitzador per ajustar els pesos del model durant l'entrenament, en funció de la taxa d'aprentatge i altres paràmetres definits\n","# La funció de pèrdues per calcular la discrepància entre les prediccions del model i les etiquetes reals\n","\n","from keras import optimizers\n","\n","rms = optimizers.RMSprop(learning_rate=0.001)    #crea una instància de l'optimitzador RMSprop amb una taxa d'aprenentatge (learning_rate) de 0.001.\n","ed_model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')     # Compila el model"]},{"cell_type":"markdown","metadata":{"id":"IuVDwSApo0VT"},"source":["Entrenem i guardem el model.\n","El model pot trigar hores si es fa a CPU, molt menys si es pot fer a GPU. Colab permet l'ús de GPU en general, si no se'n fa un ús extensiu, i es va deshabilitant l'opció i habilitant segons necessitats. Si es té activada sempre penalitza i la desactiva. Per provar si funciona, recomanem provar de llançar l'entrenament només amb una època i veure què funciona, i una vegada tenim clar que el flux està funcionant, ia llançar-ne moltes més.\n","\n","Hem vist que a Colab, tot i que demanem que la mida de sentència màxima sigui 12, no pot carregar el model en memòria i recomanem baixar-lo a 4 i el nombre d'units a 200, d'aquesta manera si que és capaç de treballar."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1muJyWc7nbO","executionInfo":{"status":"ok","timestamp":1687096075839,"user_tz":-120,"elapsed":483813,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"969a8bea-001d-4628-9514-25d150fffd0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","75/75 [==============================] - ETA: 0s - loss: 6.8085\n","Epoch 1: val_loss improved from inf to 6.40240, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 26s 233ms/step - loss: 6.8085 - val_loss: 6.4024\n","Epoch 2/30\n","74/75 [============================>.] - ETA: 0s - loss: 6.2493\n","Epoch 2: val_loss improved from 6.40240 to 6.28145, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 210ms/step - loss: 6.2482 - val_loss: 6.2814\n","Epoch 3/30\n","74/75 [============================>.] - ETA: 0s - loss: 6.0710\n","Epoch 3: val_loss improved from 6.28145 to 6.12799, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 212ms/step - loss: 6.0700 - val_loss: 6.1280\n","Epoch 4/30\n","75/75 [==============================] - ETA: 0s - loss: 5.8807\n","Epoch 4: val_loss improved from 6.12799 to 6.00654, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 219ms/step - loss: 5.8807 - val_loss: 6.0065\n","Epoch 5/30\n","73/75 [============================>.] - ETA: 0s - loss: 5.7076\n","Epoch 5: val_loss improved from 6.00654 to 5.80798, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 17s 232ms/step - loss: 5.7074 - val_loss: 5.8080\n","Epoch 6/30\n","73/75 [============================>.] - ETA: 0s - loss: 5.5111\n","Epoch 6: val_loss improved from 5.80798 to 5.65701, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 15s 208ms/step - loss: 5.5115 - val_loss: 5.6570\n","Epoch 7/30\n","74/75 [============================>.] - ETA: 0s - loss: 5.3317\n","Epoch 7: val_loss improved from 5.65701 to 5.50039, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 212ms/step - loss: 5.3328 - val_loss: 5.5004\n","Epoch 8/30\n","73/75 [============================>.] - ETA: 0s - loss: 5.1338\n","Epoch 8: val_loss improved from 5.50039 to 5.34828, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 15s 208ms/step - loss: 5.1312 - val_loss: 5.3483\n","Epoch 9/30\n","74/75 [============================>.] - ETA: 0s - loss: 4.9262\n","Epoch 9: val_loss improved from 5.34828 to 5.18022, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 211ms/step - loss: 4.9259 - val_loss: 5.1802\n","Epoch 10/30\n","75/75 [==============================] - ETA: 0s - loss: 4.7317\n","Epoch 10: val_loss improved from 5.18022 to 5.04975, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 214ms/step - loss: 4.7317 - val_loss: 5.0497\n","Epoch 11/30\n","74/75 [============================>.] - ETA: 0s - loss: 4.5492\n","Epoch 11: val_loss improved from 5.04975 to 4.92239, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 15s 207ms/step - loss: 4.5497 - val_loss: 4.9224\n","Epoch 12/30\n","74/75 [============================>.] - ETA: 0s - loss: 4.3721\n","Epoch 12: val_loss improved from 4.92239 to 4.81082, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 213ms/step - loss: 4.3726 - val_loss: 4.8108\n","Epoch 13/30\n","73/75 [============================>.] - ETA: 0s - loss: 4.2080\n","Epoch 13: val_loss improved from 4.81082 to 4.69128, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 209ms/step - loss: 4.2082 - val_loss: 4.6913\n","Epoch 14/30\n","75/75 [==============================] - ETA: 0s - loss: 4.0495\n","Epoch 14: val_loss improved from 4.69128 to 4.59799, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 211ms/step - loss: 4.0495 - val_loss: 4.5980\n","Epoch 15/30\n","74/75 [============================>.] - ETA: 0s - loss: 3.9012\n","Epoch 15: val_loss improved from 4.59799 to 4.49315, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 220ms/step - loss: 3.9009 - val_loss: 4.4932\n","Epoch 16/30\n","75/75 [==============================] - ETA: 0s - loss: 3.7610\n","Epoch 16: val_loss improved from 4.49315 to 4.40482, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 216ms/step - loss: 3.7610 - val_loss: 4.4048\n","Epoch 17/30\n","74/75 [============================>.] - ETA: 0s - loss: 3.6259\n","Epoch 17: val_loss improved from 4.40482 to 4.32344, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 210ms/step - loss: 3.6259 - val_loss: 4.3234\n","Epoch 18/30\n","73/75 [============================>.] - ETA: 0s - loss: 3.4954\n","Epoch 18: val_loss improved from 4.32344 to 4.25026, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 209ms/step - loss: 3.4971 - val_loss: 4.2503\n","Epoch 19/30\n","74/75 [============================>.] - ETA: 0s - loss: 3.3744\n","Epoch 19: val_loss improved from 4.25026 to 4.18016, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 213ms/step - loss: 3.3732 - val_loss: 4.1802\n","Epoch 20/30\n","74/75 [============================>.] - ETA: 0s - loss: 3.2503\n","Epoch 20: val_loss improved from 4.18016 to 4.12322, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 211ms/step - loss: 3.2520 - val_loss: 4.1232\n","Epoch 21/30\n","75/75 [==============================] - ETA: 0s - loss: 3.1393\n","Epoch 21: val_loss improved from 4.12322 to 4.05703, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 213ms/step - loss: 3.1393 - val_loss: 4.0570\n","Epoch 22/30\n","75/75 [==============================] - ETA: 0s - loss: 3.0303\n","Epoch 22: val_loss improved from 4.05703 to 4.00007, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 215ms/step - loss: 3.0303 - val_loss: 4.0001\n","Epoch 23/30\n","74/75 [============================>.] - ETA: 0s - loss: 2.9261\n","Epoch 23: val_loss improved from 4.00007 to 3.94797, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 210ms/step - loss: 2.9259 - val_loss: 3.9480\n","Epoch 24/30\n","75/75 [==============================] - ETA: 0s - loss: 2.8274\n","Epoch 24: val_loss improved from 3.94797 to 3.91261, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 215ms/step - loss: 2.8274 - val_loss: 3.9126\n","Epoch 25/30\n","74/75 [============================>.] - ETA: 0s - loss: 2.7311\n","Epoch 25: val_loss improved from 3.91261 to 3.86680, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 15s 209ms/step - loss: 2.7320 - val_loss: 3.8668\n","Epoch 26/30\n","75/75 [==============================] - ETA: 0s - loss: 2.6419\n","Epoch 26: val_loss improved from 3.86680 to 3.83769, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 15s 208ms/step - loss: 2.6419 - val_loss: 3.8377\n","Epoch 27/30\n","73/75 [============================>.] - ETA: 0s - loss: 2.5567\n","Epoch 27: val_loss improved from 3.83769 to 3.79097, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 212ms/step - loss: 2.5568 - val_loss: 3.7910\n","Epoch 28/30\n","73/75 [============================>.] - ETA: 0s - loss: 2.4720\n","Epoch 28: val_loss improved from 3.79097 to 3.77055, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 213ms/step - loss: 2.4724 - val_loss: 3.7706\n","Epoch 29/30\n","75/75 [==============================] - ETA: 0s - loss: 2.3941\n","Epoch 29: val_loss improved from 3.77055 to 3.73050, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 213ms/step - loss: 2.3941 - val_loss: 3.7305\n","Epoch 30/30\n","73/75 [============================>.] - ETA: 0s - loss: 2.3151\n","Epoch 30: val_loss improved from 3.73050 to 3.71125, saving model to model_en_du\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 212ms/step - loss: 2.3183 - val_loss: 3.7113\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fae7e32db40>"]},"metadata":{},"execution_count":14}],"source":["#############################################\n","# SOLUCIÓ                                  #\n","#############################################\n","\n","# Entrenem y guardem el model\n","# ModelCheckpoint permet guardar el model durant l'entrenament en funció de certes condicions\n","from keras.callbacks import ModelCheckpoint\n","\n","model_path = 'model_en_du'   # Path on es guardarà el model\n","# Creem instància de 'ModelCheckpoint'\n","# model_path: ruta on es guardarà el model.\n","# verbose=1: Mostra infomació detallada sobre el procès de guardat\n","# save_best_only=True: només es guarda el millor model segons la mètrica de seguiment (en aquest cas, la pèrdua mínima en el conjunt de validació).\n","# mode='min': es desa el model quan la mètrica de seguiment es minimitza.\n","checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","# Entrenament del model 'ed_model' fent servir les dades d'entrenament trainX i trainY\n","# epochs=30: Número d'epoques d'entrenament\n","# batch_size=512: model del lot o batch fet servir durant l'entrenament\n","# validation_split = 0.2 proporció de les dades d'entrenament que es faran servir com a conjunt de validació.\n","# callbacks: es passa l'objecte ModelCheckpoint durant l'entrenament per desar el model.\n","# verbose =1:  es mostra informació detallada durant l'entrenament.\n","ed_model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], verbose=1)\n"]},{"cell_type":"markdown","metadata":{"id":"-Rnmfh3GpdJ0"},"source":["Un cop entrenat el model, s'aplica amb el conjunt de tests per obtenir unes predicions."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"QX74wIEu7nbP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687096313810,"user_tz":-120,"elapsed":6517,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"e89f2430-4c35-4fae-c1cc-860309279a62"},"outputs":[{"output_type":"stream","name":"stdout","text":["375/375 [==============================] - 2s 3ms/step\n","[[  10    4   28  291]\n"," [  41    5    5   81]\n"," [  63   13   47 2219]\n"," ...\n"," [   4    4    4 1156]\n"," [   1   13   92  158]\n"," [   6    6  751   21]]\n"]}],"source":["#############################################\n","# Realitzem prediccions fent servir el model entrenat 'ed_model'  en un conjunt de dades de prova\n","import numpy as np\n","\n","# np.argmax: per obtenir l'índex de la classe amb més probabilitat per a cada exemple de prova. Els índexs de les classes amb més probabilitat s'assignen a la variable preds.\n","predicts = np.argmax(ed_model.predict(testX.reshape((testX.shape[0],testX.shape[1]))), axis=-1)\n","print(predicts)"]},{"cell_type":"markdown","metadata":{"id":"Drwik5f5pllA"},"source":["Visualitzem els resultats de les prediccions amb els valors esperats. Els resultats són curiosos, no podríem fer servir aquest model per a un entorn real com podreu veure.\n","\n","Pregunta: Perquè creieu que no són bons, i com creieu que podrien obtenir-se millors resultats?"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Se_zdVHz7nbP","colab":{"base_uri":"https://localhost:8080/","height":833},"executionInfo":{"status":"ok","timestamp":1687096315979,"user_tz":-120,"elapsed":220,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"dbe6a0bd-ef6b-4886-d16d-2d55b7aed371"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              Current  \\\n","0                              hoelang heeft u dit al   \n","1                ik heb het huis nog niet gerenoveerd   \n","2                        ik hou van amerikaanse films   \n","3                                hoe is dat jouw fout   \n","4                                heeft tom geantwoord   \n","5     tom heeft nauwelijks voor het examen gestudeerd   \n","6                         weet hij wat je hebt gedaan   \n","7                   ik vertel je alleen wat ik hoorde   \n","8   ik vraag me af of tom doof aan het worden is o...   \n","9                                         ik eet niet   \n","10               we hebben je over een paar uur nodig   \n","11       ik kreeg te horen dat ik dat niet mocht doen   \n","12                          je kunt er zelf een maken   \n","13                             frans is moeilijk toch   \n","14                   heb je dit ook in andere kleuren   \n","15                              tom zette de ketel op   \n","16                             betaal je huur vooruit   \n","17                  ik wens je een gelukkig nieuwjaar   \n","18                              hoeveel hebt ge nodig   \n","19                 hij betreurde zijn beslissing niet   \n","20                                  gelooft u me niet   \n","21                                 wie heeft jouw pas   \n","22                            tom werd geïnteresseerd   \n","23               hebt ge de toren van tokio al gezien   \n","24                                ben je er zeker van   \n","\n","                       predicted  \n","0            heb je dit gevonden  \n","1                  nog het  huis  \n","2     hou van deze chocolademelk  \n","3               zijn dat  jullie  \n","4          heeft tom gereageerd   \n","5              voor  het feestje  \n","6                   wat je hebt   \n","7                    wat  ik heb  \n","8                   tom is dood   \n","9                   ik eet niet   \n","10                 een  paar uur  \n","11                dat niet  doen  \n","12              je  kunnen maken  \n","13                     is  niet   \n","14           in de andere dollar  \n","15         ik het water opzetten  \n","16              je  laten vallen  \n","17  een goede gelukkig nieuwjaar  \n","18             hoeveel je  nodig  \n","19           niet van de gemaakt  \n","20               geloof me  niet  \n","21            wie je  geschreven  \n","22        tom werd geïntrigeerd   \n","23              ooit een gezien   \n","24            je niet zeker over  "],"text/html":["\n","  <div id=\"df-9e763699-e4ec-497b-a4f0-dd9a70a882bc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Current</th>\n","      <th>predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>hoelang heeft u dit al</td>\n","      <td>heb je dit gevonden</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ik heb het huis nog niet gerenoveerd</td>\n","      <td>nog het  huis</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ik hou van amerikaanse films</td>\n","      <td>hou van deze chocolademelk</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>hoe is dat jouw fout</td>\n","      <td>zijn dat  jullie</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>heeft tom geantwoord</td>\n","      <td>heeft tom gereageerd</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>tom heeft nauwelijks voor het examen gestudeerd</td>\n","      <td>voor  het feestje</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>weet hij wat je hebt gedaan</td>\n","      <td>wat je hebt</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>ik vertel je alleen wat ik hoorde</td>\n","      <td>wat  ik heb</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>ik vraag me af of tom doof aan het worden is o...</td>\n","      <td>tom is dood</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>ik eet niet</td>\n","      <td>ik eet niet</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>we hebben je over een paar uur nodig</td>\n","      <td>een  paar uur</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>ik kreeg te horen dat ik dat niet mocht doen</td>\n","      <td>dat niet  doen</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>je kunt er zelf een maken</td>\n","      <td>je  kunnen maken</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>frans is moeilijk toch</td>\n","      <td>is  niet</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>heb je dit ook in andere kleuren</td>\n","      <td>in de andere dollar</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>tom zette de ketel op</td>\n","      <td>ik het water opzetten</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>betaal je huur vooruit</td>\n","      <td>je  laten vallen</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>ik wens je een gelukkig nieuwjaar</td>\n","      <td>een goede gelukkig nieuwjaar</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>hoeveel hebt ge nodig</td>\n","      <td>hoeveel je  nodig</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>hij betreurde zijn beslissing niet</td>\n","      <td>niet van de gemaakt</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>gelooft u me niet</td>\n","      <td>geloof me  niet</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>wie heeft jouw pas</td>\n","      <td>wie je  geschreven</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>tom werd geïnteresseerd</td>\n","      <td>tom werd geïntrigeerd</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>hebt ge de toren van tokio al gezien</td>\n","      <td>ooit een gezien</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>ben je er zeker van</td>\n","      <td>je niet zeker over</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e763699-e4ec-497b-a4f0-dd9a70a882bc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9e763699-e4ec-497b-a4f0-dd9a70a882bc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9e763699-e4ec-497b-a4f0-dd9a70a882bc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}],"source":["#############################################\n","# Visualitzem resultats\n","import pandas as pd\n","\n","def get_word(n, tokenizer):\n","    for word, index in tokenizer.word_index.items():\n","        if index == n:\n","            return word\n","    return None\n","\n","preds_du = []\n","\n","for i in predicts[:25]:\n","    temp = []\n","    for j in range(len(i)):\n","        t = get_word(i[j], dutch_tokenizer)\n","        if j > 0:\n","            if (t == get_word(i[j-1], dutch_tokenizer)) or (t == None):\n","                     temp.append('')\n","            else:\n","                     temp.append(t)\n","        else:\n","            if(t == None):\n","                temp.append('')\n","            else:\n","                temp.append(t)\n","\n","    preds_du.append(' '.join(temp))\n","\n","predicció = pd.DataFrame({'Current' : test[:,1][:25], 'predicted' : preds_du})\n","predicció"]},{"cell_type":"markdown","metadata":{"id":"LCDwpoa5JI3s"},"source":["**Pregunta: Perquè creieu que no són bons, i com creieu que podrien obtenir-se millors resultats?**\n","\n","Les prediccions no son bones degut a que els valors predits no coincideixen amb els valors reals. Hi ha eliminació de paraules, apareixen altres paraules que no hi eren, etc.\n","\n","Això pot haver sigut per diversos motius:\n","- **Per un entrenament insuficient**: Quan el model no ha estat prou entrenat o la quantitat de dades d'entrenament no eren suficients per aprendre les relacions i els patrons en el text.\n","- **Grandària inadequada del conjunt de dades**: Si el conjunt de dades utilitzat per entrenar el model no representa adequadament la variabilitat i diversitat del llenguatge, el que dificulta fer prediccions precises en nous exemples.\n","- **Modelat inadequat del problema**: L'arquitectura del model o els hiperparàmetres utilitzats poden no ser els més adequats per al problema en qüestió. És possible que es requereixi una arquitectura més complexa o una configuració diferent dels hiperparàmetres per millorar les prediccions.\n","- **Sobreajustament (overfitting)**: Si el model s'ha sobreajustat a les dades d'entrenament, és a dir, quan ha memoritzat els exemples d'entrenament en lloc d'aprendre patrons generals, pot tenir dificultats per generalitzar nous exemples i produir prediccions precises.\n","\n","**Per obtenir millors resultats:**\n","\n","- Revisar i ampliar el conjunt de dades d'entrenament per garantir una representativitat i diversitat més gran del llenguatge.\n","- Augmentar el nombre d'èpoques d'entrenament o provar-ho amb diferents arquitectures i configuracions d'hiperparàmetres.\n","- Considerar l'ús de tècniques de regularització, com la incorporació de capes de dropout, per evitar el sobreajustament.\n","- Avaluar i ajustar l'exercici del model mitjançant mètriques d'avaluació adequades i anàlisi detallada dels errors comesos.\n"]},{"cell_type":"markdown","metadata":{"id":"Re2z6jLm7nbP"},"source":["## 1.2 TA amb Embeddings preentrenats (2 punts)"]},{"cell_type":"markdown","metadata":{"id":"_zzbdDJq7nbP"},"source":["En aquest apartat repetirem l'exercici anterior carregant a la capa d'embedding els pesos d‟un model GloVe entrenat per l'anglès."]},{"cell_type":"markdown","metadata":{"id":"9vncpo5D7nbP"},"source":["Comencem carregant el model GloVe per a l'anglès. Podeu fer servir 'glove.42B.300d.txt' baixant-lo d'aquí https://nlp.stanford.edu/projects/glove/."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Oops18MJ7nbR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687096472875,"user_tz":-120,"elapsed":149282,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"cc8ea9d4-41bb-45ce-db0a-8dbf2d416e2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["1917494\n"]}],"source":["import numpy as np\n","\n","embeddings_index = {}\n","try:\n","  f = open('glove.42B.300d.txt')\n","except:\n","  f = open('/content/drive/MyDrive/glove.42B.300d.txt')\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","f.close()\n","\n","print(len(embeddings_index))"]},{"cell_type":"markdown","metadata":{"id":"kajSHKSH7nbR"},"source":["Tot seguit, hem de construir la matriu d'embeddings.\n","Per no carregar tot el vocabulari del model, podem filtrar només aquelles entrades presents al vocabulari del tokenitzador que farem servir. A més, hem d'incloure a la matriu de vectors corresponents els índexs de les entrades (paraules) que no trobem al model glove carregat. Aquests vectors se solen inicialitzar amb 0 o amb el resultat d'una distribució N(0,1)"]},{"cell_type":"markdown","metadata":{"id":"snHfP3Cb7nbR"},"source":["Per exemple, si el nostre tokenitzador es digués `eng_tokenizer` podríem fer:"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"MiQ797NU7nbR","executionInfo":{"status":"ok","timestamp":1687096734838,"user_tz":-120,"elapsed":249,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}}},"outputs":[],"source":["embedding_matrix = np.zeros((len(eng_tokenizer.word_index) + 1, 300))\n","for word, i in eng_tokenizer.word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector\n"]},{"cell_type":"markdown","metadata":{"id":"tMMsDFOy7nbR"},"source":["Per inicialitzar una capa d'embeddings amb pesos predefinits s'utilitza l'argument weights. A més, com que no volem que es modifiquin els pesos, marquem l'argument `trainable` com `False`.\n","\n","Seguint amb el nostre exemple, faríem:"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"QLjfzHAq7nbR","executionInfo":{"status":"ok","timestamp":1687096739886,"user_tz":-120,"elapsed":231,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}}},"outputs":[],"source":["from keras.layers import Embedding\n","\n","embed_vec_length = 300\n","embedding_layer = Embedding(len(eng_tokenizer.word_index) + 1,\n","                            embed_vec_length,\n","                            weights=[embedding_matrix],\n","                            input_length=max_text_len,\n","                            trainable=False,\n","                            mask_zero=True)\n"]},{"cell_type":"markdown","metadata":{"id":"2TAaf6I77nbR"},"source":["Implementa i entrena de nou un model de traducció automàtica de l'anglès al holandès de manera similar, aquesta vegada carregant els pesos de la capa embedding a partir del model Glove preentrenat en anglès i disponible a 'glove.42B.300d.txt'."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"9hKTQCdp7nbS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687096744494,"user_tz":-120,"elapsed":1499,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"9002264d-2a65-4bed-b0ec-8de13dc1addb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 4, 300)            2513100   \n","                                                                 \n"," lstm_2 (LSTM)               (None, 300)               721200    \n","                                                                 \n"," repeat_vector_1 (RepeatVect  (None, 4, 300)           0         \n"," or)                                                             \n","                                                                 \n"," lstm_3 (LSTM)               (None, 4, 300)            721200    \n","                                                                 \n"," dense_1 (Dense)             (None, 4, 11753)          3537653   \n","                                                                 \n","=================================================================\n","Total params: 7,493,153\n","Trainable params: 4,980,053\n","Non-trainable params: 2,513,100\n","_________________________________________________________________\n","None\n"]}],"source":["#############################################\n","# SOLUCIÓN                                  #\n","#############################################\n","from keras.models import Sequential     # per crear un model seqüèncial\n","from keras.layers import Dense, LSTM, Embedding, RepeatVector    # per afegir diferents capes al model\n","\n","from keras import optimizers\n","\n","def def_model(embedding_layer, embedding_vec_length, max_text_length, out_vocab_size):\n","    mt_model2 = Sequential()\n","    mt_model2.add(embedding_layer)\n","    mt_model2.add(LSTM(embedding_vec_length))\n","    mt_model2.add(RepeatVector(max_text_length))\n","    mt_model2.add(LSTM(embedding_vec_length, return_sequences=True))\n","    mt_model2.add(Dense(out_vocab_size, activation='softmax'))\n","    return mt_model2\n","\n","mt_model2 = def_model(embedding_layer, embed_vec_length, max_text_len, dutch_vocab_size)\n","print(mt_model2.summary())\n","\n","rms = optimizers.RMSprop(learning_rate=0.001)\n","mt_model2.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"]},{"cell_type":"markdown","metadata":{"id":"PqyHV6m3rIUn"},"source":["Entrenem i guardem el model. Un altre cop, encara que aquest entrenament és potser un \"poc\" més lleuger que l'anterior, recomanem l'ús de GPU si és viable."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"l58sRZaY7nbS","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687097194771,"user_tz":-120,"elapsed":445727,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"44ba1c4d-6915-414f-ce20-e48f140bd77c"},"outputs":[{"output_type":"stream","name":"stdout","text":["(48000, 4)\n","48000\n","4\n","Epoch 1/30\n","75/75 [==============================] - ETA: 0s - loss: 6.5351\n","Epoch 1: val_loss improved from inf to 6.22039, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 22s 246ms/step - loss: 6.5351 - val_loss: 6.2204\n","Epoch 2/30\n","75/75 [==============================] - ETA: 0s - loss: 5.9470\n","Epoch 2: val_loss improved from 6.22039 to 5.82517, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 17s 228ms/step - loss: 5.9470 - val_loss: 5.8252\n","Epoch 3/30\n","75/75 [==============================] - ETA: 0s - loss: 5.4283\n","Epoch 3: val_loss improved from 5.82517 to 5.35110, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 220ms/step - loss: 5.4283 - val_loss: 5.3511\n","Epoch 4/30\n","75/75 [==============================] - ETA: 0s - loss: 4.9602\n","Epoch 4: val_loss improved from 5.35110 to 4.97373, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 221ms/step - loss: 4.9602 - val_loss: 4.9737\n","Epoch 5/30\n","75/75 [==============================] - ETA: 0s - loss: 4.5300\n","Epoch 5: val_loss improved from 4.97373 to 4.64954, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 220ms/step - loss: 4.5300 - val_loss: 4.6495\n","Epoch 6/30\n","75/75 [==============================] - ETA: 0s - loss: 4.1608\n","Epoch 6: val_loss improved from 4.64954 to 4.40467, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 222ms/step - loss: 4.1608 - val_loss: 4.4047\n","Epoch 7/30\n","75/75 [==============================] - ETA: 0s - loss: 3.8464\n","Epoch 7: val_loss improved from 4.40467 to 4.17040, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 219ms/step - loss: 3.8464 - val_loss: 4.1704\n","Epoch 8/30\n","75/75 [==============================] - ETA: 0s - loss: 3.5825\n","Epoch 8: val_loss improved from 4.17040 to 4.00817, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 221ms/step - loss: 3.5825 - val_loss: 4.0082\n","Epoch 9/30\n","75/75 [==============================] - ETA: 0s - loss: 3.3502\n","Epoch 9: val_loss improved from 4.00817 to 3.83204, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 17s 225ms/step - loss: 3.3502 - val_loss: 3.8320\n","Epoch 10/30\n","75/75 [==============================] - ETA: 0s - loss: 3.1455\n","Epoch 10: val_loss improved from 3.83204 to 3.71640, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 221ms/step - loss: 3.1455 - val_loss: 3.7164\n","Epoch 11/30\n","75/75 [==============================] - ETA: 0s - loss: 2.9616\n","Epoch 11: val_loss improved from 3.71640 to 3.63285, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 17s 224ms/step - loss: 2.9616 - val_loss: 3.6328\n","Epoch 12/30\n","75/75 [==============================] - ETA: 0s - loss: 2.8003\n","Epoch 12: val_loss improved from 3.63285 to 3.52889, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 219ms/step - loss: 2.8003 - val_loss: 3.5289\n","Epoch 13/30\n","75/75 [==============================] - ETA: 0s - loss: 2.6531\n","Epoch 13: val_loss improved from 3.52889 to 3.44784, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 222ms/step - loss: 2.6531 - val_loss: 3.4478\n","Epoch 14/30\n","75/75 [==============================] - ETA: 0s - loss: 2.5187\n","Epoch 14: val_loss improved from 3.44784 to 3.38790, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 219ms/step - loss: 2.5187 - val_loss: 3.3879\n","Epoch 15/30\n","75/75 [==============================] - ETA: 0s - loss: 2.3899\n","Epoch 15: val_loss improved from 3.38790 to 3.33879, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 17s 232ms/step - loss: 2.3899 - val_loss: 3.3388\n","Epoch 16/30\n","75/75 [==============================] - ETA: 0s - loss: 2.2754\n","Epoch 16: val_loss improved from 3.33879 to 3.29610, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 221ms/step - loss: 2.2754 - val_loss: 3.2961\n","Epoch 17/30\n","75/75 [==============================] - ETA: 0s - loss: 2.1660\n","Epoch 17: val_loss improved from 3.29610 to 3.26348, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 17s 226ms/step - loss: 2.1660 - val_loss: 3.2635\n","Epoch 18/30\n","75/75 [==============================] - ETA: 0s - loss: 2.0635\n","Epoch 18: val_loss improved from 3.26348 to 3.23472, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 17s 224ms/step - loss: 2.0635 - val_loss: 3.2347\n","Epoch 19/30\n","75/75 [==============================] - ETA: 0s - loss: 1.9653\n","Epoch 19: val_loss improved from 3.23472 to 3.19535, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 17s 230ms/step - loss: 1.9653 - val_loss: 3.1953\n","Epoch 20/30\n","75/75 [==============================] - ETA: 0s - loss: 1.8739\n","Epoch 20: val_loss improved from 3.19535 to 3.17315, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 221ms/step - loss: 1.8739 - val_loss: 3.1732\n","Epoch 21/30\n","75/75 [==============================] - ETA: 0s - loss: 1.7876\n","Epoch 21: val_loss improved from 3.17315 to 3.16830, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 17s 223ms/step - loss: 1.7876 - val_loss: 3.1683\n","Epoch 22/30\n","75/75 [==============================] - ETA: 0s - loss: 1.7063\n","Epoch 22: val_loss improved from 3.16830 to 3.14725, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 219ms/step - loss: 1.7063 - val_loss: 3.1473\n","Epoch 23/30\n","75/75 [==============================] - ETA: 0s - loss: 1.6304\n","Epoch 23: val_loss improved from 3.14725 to 3.14530, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 17s 226ms/step - loss: 1.6304 - val_loss: 3.1453\n","Epoch 24/30\n","75/75 [==============================] - ETA: 0s - loss: 1.5577\n","Epoch 24: val_loss improved from 3.14530 to 3.12791, saving model to model_en_du-2\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/75 [==============================] - 16s 219ms/step - loss: 1.5577 - val_loss: 3.1279\n","Epoch 25/30\n","75/75 [==============================] - ETA: 0s - loss: 1.4872\n","Epoch 25: val_loss did not improve from 3.12791\n","75/75 [==============================] - 3s 33ms/step - loss: 1.4872 - val_loss: 3.1373\n","Epoch 26/30\n","75/75 [==============================] - ETA: 0s - loss: 1.4216\n","Epoch 26: val_loss did not improve from 3.12791\n","75/75 [==============================] - 2s 33ms/step - loss: 1.4216 - val_loss: 3.1434\n","Epoch 27/30\n","75/75 [==============================] - ETA: 0s - loss: 1.3603\n","Epoch 27: val_loss did not improve from 3.12791\n","75/75 [==============================] - 2s 33ms/step - loss: 1.3603 - val_loss: 3.1308\n","Epoch 28/30\n","75/75 [==============================] - ETA: 0s - loss: 1.2991\n","Epoch 28: val_loss did not improve from 3.12791\n","75/75 [==============================] - 3s 35ms/step - loss: 1.2991 - val_loss: 3.1480\n","Epoch 29/30\n","75/75 [==============================] - ETA: 0s - loss: 1.2422\n","Epoch 29: val_loss did not improve from 3.12791\n","75/75 [==============================] - 3s 35ms/step - loss: 1.2422 - val_loss: 3.1382\n","Epoch 30/30\n","75/75 [==============================] - ETA: 0s - loss: 1.1875\n","Epoch 30: val_loss did not improve from 3.12791\n","75/75 [==============================] - 2s 33ms/step - loss: 1.1875 - val_loss: 3.1701\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fae7e39cc40>"]},"metadata":{},"execution_count":21}],"source":["#############################################\n","# SOLUCIÓN                                  #\n","#############################################\n","\n","from keras.callbacks import ModelCheckpoint\n","\n","# trainX té una mida de matriu on el primer valor es el número de mostres i la segona dimensió la longitut de cada mostra\n","print(trainX.shape)\n","print(trainY.shape[0])\n","print(trainY.shape[1])\n","\n","model_path = 'model_en_du-2'\n","checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","mt_model2.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], verbose=1)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wW-2Cnuqrbsu"},"source":["Aplicar el model i visualitzar-ne els resultats a partir de les predicions obtingudes amb aquest nou model."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"efztL7bg7nbT","colab":{"base_uri":"https://localhost:8080/","height":851},"executionInfo":{"status":"ok","timestamp":1687097333313,"user_tz":-120,"elapsed":13429,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"bf5a8c48-1985-4a51-faa3-63fc9734e9f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["375/375 [==============================] - 3s 3ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["                                              Current  \\\n","0                              hoelang heeft u dit al   \n","1                ik heb het huis nog niet gerenoveerd   \n","2                        ik hou van amerikaanse films   \n","3                                hoe is dat jouw fout   \n","4                                heeft tom geantwoord   \n","5     tom heeft nauwelijks voor het examen gestudeerd   \n","6                         weet hij wat je hebt gedaan   \n","7                   ik vertel je alleen wat ik hoorde   \n","8   ik vraag me af of tom doof aan het worden is o...   \n","9                                         ik eet niet   \n","10               we hebben je over een paar uur nodig   \n","11       ik kreeg te horen dat ik dat niet mocht doen   \n","12                          je kunt er zelf een maken   \n","13                             frans is moeilijk toch   \n","14                   heb je dit ook in andere kleuren   \n","15                              tom zette de ketel op   \n","16                             betaal je huur vooruit   \n","17                  ik wens je een gelukkig nieuwjaar   \n","18                              hoeveel hebt ge nodig   \n","19                 hij betreurde zijn beslissing niet   \n","20                                  gelooft u me niet   \n","21                                 wie heeft jouw pas   \n","22                            tom werd geïnteresseerd   \n","23               hebt ge de toren van tokio al gezien   \n","24                                ben je er zeker van   \n","\n","                   predicted  \n","0              heb je dit al  \n","1              huis  al huis  \n","2           ik hou van films  \n","3                is  jouw is  \n","4      heeft tom gereageerd   \n","5        heb voor het examen  \n","6               wat je hebt   \n","7              wat  gehoord   \n","8               tom is niet   \n","9               ik eet niet   \n","10       een enkele over aan  \n","11       dat niet mocht doen  \n","12        je een uzelf maken  \n","13           is  te nietwaar  \n","14      in van andere elkaar  \n","15    zet het water opzetten  \n","16          uw  huur vooruit  \n","17   een  gelukkig nieuwjaar  \n","18      hoeveel heb je nodig  \n","19  zijn van niet beslissing  \n","20         geloof je me niet  \n","21     wie heeft je paspoort  \n","22    tom werd geïntrigeerd   \n","23      ooit een eens gezien  \n","24                je  zeker   "],"text/html":["\n","  <div id=\"df-33e73d2e-4c20-432b-85fe-6c2943484cbd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Current</th>\n","      <th>predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>hoelang heeft u dit al</td>\n","      <td>heb je dit al</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ik heb het huis nog niet gerenoveerd</td>\n","      <td>huis  al huis</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ik hou van amerikaanse films</td>\n","      <td>ik hou van films</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>hoe is dat jouw fout</td>\n","      <td>is  jouw is</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>heeft tom geantwoord</td>\n","      <td>heeft tom gereageerd</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>tom heeft nauwelijks voor het examen gestudeerd</td>\n","      <td>heb voor het examen</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>weet hij wat je hebt gedaan</td>\n","      <td>wat je hebt</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>ik vertel je alleen wat ik hoorde</td>\n","      <td>wat  gehoord</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>ik vraag me af of tom doof aan het worden is o...</td>\n","      <td>tom is niet</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>ik eet niet</td>\n","      <td>ik eet niet</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>we hebben je over een paar uur nodig</td>\n","      <td>een enkele over aan</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>ik kreeg te horen dat ik dat niet mocht doen</td>\n","      <td>dat niet mocht doen</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>je kunt er zelf een maken</td>\n","      <td>je een uzelf maken</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>frans is moeilijk toch</td>\n","      <td>is  te nietwaar</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>heb je dit ook in andere kleuren</td>\n","      <td>in van andere elkaar</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>tom zette de ketel op</td>\n","      <td>zet het water opzetten</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>betaal je huur vooruit</td>\n","      <td>uw  huur vooruit</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>ik wens je een gelukkig nieuwjaar</td>\n","      <td>een  gelukkig nieuwjaar</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>hoeveel hebt ge nodig</td>\n","      <td>hoeveel heb je nodig</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>hij betreurde zijn beslissing niet</td>\n","      <td>zijn van niet beslissing</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>gelooft u me niet</td>\n","      <td>geloof je me niet</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>wie heeft jouw pas</td>\n","      <td>wie heeft je paspoort</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>tom werd geïnteresseerd</td>\n","      <td>tom werd geïntrigeerd</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>hebt ge de toren van tokio al gezien</td>\n","      <td>ooit een eens gezien</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>ben je er zeker van</td>\n","      <td>je  zeker</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33e73d2e-4c20-432b-85fe-6c2943484cbd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-33e73d2e-4c20-432b-85fe-6c2943484cbd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-33e73d2e-4c20-432b-85fe-6c2943484cbd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}],"source":["#############################################\n","# SOLUCIÓ                                  #\n","#############################################\n","import pandas as pd\n","\n","predicts = np.argmax(mt_model2.predict(testX.reshape((testX.shape[0],testX.shape[1]))), axis=-1)\n","\n","\n","def get_word(n, tokenizer):\n","    for word, index in tokenizer.word_index.items():\n","        if index == n:\n","            return word\n","    return None\n","\n","preds_du = []\n","\n","for i in predicts[:25]:\n","    xx = []\n","    for j in range(len(i)):\n","        t = get_word(i[j], dutch_tokenizer)\n","        if j > 0:\n","            if (t == get_word(i[j-1], dutch_tokenizer)) or (t == None):\n","                     xx.append('')\n","            else:\n","                     xx.append(t)\n","        else:\n","            if(t == None):\n","                xx.append('')\n","            else:\n","                xx.append(t)\n","\n","    preds_du.append(' '.join(xx))\n","\n","predicció = pd.DataFrame({'Current' : test[:,1][:25], 'predicted' : preds_du})\n","predicció"]},{"cell_type":"markdown","metadata":{"id":"Y0n1SFEj7nbT"},"source":["<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n","<strong>(Opcional) Anàlisi:</strong> Explica quines són les principals diferències entre els dos models entrenats. Com podríem millorar els resultats d'aquesta tasca concreta?\n","</div>\n","\n","**RESPOSTA:**\n","En el segon model, les predicción s'apropen més als valors actuals i presenten menys errors.\n","En aquest segon model també es dona inversió de l'ordre de les paraules, com al cas '2-het moet gewassen worden' o la omissió d'alguna paraula com al cas '6-ik voelde me'. Però en general, la majoria de les prediccions son més precisses i s'assemblen més als valors actuals.\n","Per tant, el segon model sembla que té un rendiment millorat en comparació amb el primer model, per generar prediccions més properes als valors reals.\n","\n","*Per millorar els resultats d'aquesta tasca concreta es podria aplica el següent*:\n","\n","1.- Augmentar la mida i la qualitat del conjunt de dades d'entrenament: ja que així el model pot aprendre patrons més precisos i generar millors prediccions. Per tant, cal recopilar més exemples de frases en els dos idiomes i garantir la diversistat de les dades.\n","\n","2.- Fer un preprocessament de dades més exhaustiu: cal garantir que els models reben dades netes i correctament formatejades. Com eliminar caràcters no desitjats, normalització del texte, correcció d'errors ortogràfics, etc.\n","\n","3.- Provar amb diferents arquitectures de models: provar diferents arquitectures de xarxes neuronals i ajustar els hiperparàmetres per trobar la configuració óptima per aquesta tasca específica.\n","\n","4.- Ajustar els hiperparàmetres del model: la taxa d'aprenentatge, la mida del lot, el nombre de capes ocultes, la mida de les capes, etc, ja que poden influir en el rendiment del model.\n","\n","5.- Fer servir tècniques avançades de NPL: com l'ús de models de llenguatges preentrenats, atenció, mecanismes de traducció per millorar la qualitat de les prediccions.\n","\n","6.- Realitzar avaluació detallada i anàlisis d'errors: cal analitzar els errors comesos pel model per entendre les àrees en que està fallant i prendre mides correctives específiques. El que pot implicar la identificació de patrons cmuns en els errors i la iteració en el procès de millora del model.\n","\n","Finalment, per millorar el rendiment en tasques de traducció automàtica es important provar diferents enfocs i tècniques per trobar la combinació que funcioni millor per les dades i els requisits específics de les tasques."]},{"cell_type":"markdown","metadata":{"id":"IcJ5JpIXuE9M"},"source":["# PART 2\n"]},{"cell_type":"markdown","metadata":{"id":"LpiJOV3MxHQQ"},"source":["# 2. Classificació de notícies (4 punts)\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"iwA-vzTklXP0"},"source":["En aquest apartat plantegem l'ús de les arquitectures vistes fins ara per crear un classificador de notícies en anglès.\n","En concret farem servir aquest dataset:\n","https://www.kaggle.com/datasets/rmisra/news-category-dataset\n","És un dataset de classificació que té 42 categories. Ens enfocarem en 6 d'elles. En concret les següents:\n","+ HEALTHY LIVING\n","+ VOLER VOICES\n","+ FOOD & DRINK\n","+ BUSINESS\n","+ COMEDY\n","+ SPORTS"]},{"cell_type":"markdown","metadata":{"id":"dACMx1zAN4qc"},"source":["## 2.1 Preparar dades classificació notícies (1 punt)\n","\n","El primer que farem serà obtenir el dataset, agafar l'arxiu, llegir-lo des d'un dataframe pandes, agafar les columnes “headline” i “category”.\n","\n","Samplejar el corpus i agafar només les 1000 primeres entrades perquè l'script vagi més ràpid. Més endavant podrem realitzar proves per veure si afegint més entrades tenim millors resultats. Òbviament les entrades, després es repartiran per les categories que hem escollit."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"VRtrYA3nlXP1","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1687097353398,"user_tz":-120,"elapsed":2370,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"fd0ef4a3-5328-4561-d09c-d25a96236869"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              headline        category\n","0     13 Ways To Make Collard Greens Totally Delicious    FOOD & DRINK\n","1    Proposed \"Spot The Conspiracy Theory\" Test for...          COMEDY\n","2    The 50 Best Craft Beers In America In 2013, Ac...    FOOD & DRINK\n","3    REMINDER: Michigan Taught Notre Dame How To Pl...          SPORTS\n","4    Sriracha Oatmeal May Be Our New Favorite Savor...    FOOD & DRINK\n","..                                                 ...             ...\n","995  U.S.A. Beats Germany 2-0 To Advance To Women's...          SPORTS\n","996  This Political Polarization Is Really Bad for ...        BUSINESS\n","997  Jason Collins, Robbie Rogers And Others Celebr...          SPORTS\n","998  Can Being in Love Make You Fat?  Plus, 10 Sugg...  HEALTHY LIVING\n","999  iHeartMedia Files For Chapter 11 Bankruptcy Pr...        BUSINESS\n","\n","[1000 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-b5e84ab3-cad5-4fb9-bc5a-5da1c9c9b826\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headline</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13 Ways To Make Collard Greens Totally Delicious</td>\n","      <td>FOOD &amp; DRINK</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Proposed \"Spot The Conspiracy Theory\" Test for...</td>\n","      <td>COMEDY</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The 50 Best Craft Beers In America In 2013, Ac...</td>\n","      <td>FOOD &amp; DRINK</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>REMINDER: Michigan Taught Notre Dame How To Pl...</td>\n","      <td>SPORTS</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sriracha Oatmeal May Be Our New Favorite Savor...</td>\n","      <td>FOOD &amp; DRINK</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>U.S.A. Beats Germany 2-0 To Advance To Women's...</td>\n","      <td>SPORTS</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>This Political Polarization Is Really Bad for ...</td>\n","      <td>BUSINESS</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>Jason Collins, Robbie Rogers And Others Celebr...</td>\n","      <td>SPORTS</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>Can Being in Love Make You Fat?  Plus, 10 Sugg...</td>\n","      <td>HEALTHY LIVING</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>iHeartMedia Files For Chapter 11 Bankruptcy Pr...</td>\n","      <td>BUSINESS</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5e84ab3-cad5-4fb9-bc5a-5da1c9c9b826')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b5e84ab3-cad5-4fb9-bc5a-5da1c9c9b826 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b5e84ab3-cad5-4fb9-bc5a-5da1c9c9b826');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}],"source":["\n","#############################################\n","# SOLUCIÓ                               #\n","#############################################\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","try:\n","  df=pd.read_json('/content/drive/MyDrive/News_Category_Dataset_v3.json', lines=True)\n","except:\n","  df=pd.read_json('/content/News_Category_Dataset_v3.json', lines=True)\n","\n","\n","selected_categories = ['HEALTHY LIVING', 'VOLER VOICES', 'FOOD & DRINK', 'BUSINESS', 'COMEDY', 'SPORTS']\n","\n","# Filtrem el Dataset per les 6 categories que ens interessen\n","df_selected = df[df['category'].isin(selected_categories)]\n","\n","# creem un train_df amb stratify per category per tenir quantitats semblants\n","train_df, _ = train_test_split(df_selected, train_size=1000, stratify=df_selected['category'], random_state=42)\n","\n","# Reset the index of the selected DataFrame\n","df_selected = train_df.reset_index(drop=True)\n","\n","selected_columns = ['headline', 'category']\n","df_selected = df_selected.loc[:, selected_columns]\n","\n","df_selected"]},{"cell_type":"markdown","metadata":{"id":"eszZbTJRR2p1"},"source":["Visualitzeu la distribució de textos per classe."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"N6W_dKhLR19N","colab":{"base_uri":"https://localhost:8080/","height":663},"executionInfo":{"status":"ok","timestamp":1687097359667,"user_tz":-120,"elapsed":740,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"ff1223a2-2336-4546-f02b-fc1b8a021a2d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["#############################################\n","# SOLUCIÓ                                #\n","#############################################\n","\n","import matplotlib.pyplot as plt\n","\n","# Count the number of headlines per category\n","category_counts = df_selected['category'].value_counts()\n","\n","# Plot the histogram\n","plt.figure(figsize=(10, 6))\n","plt.bar(category_counts.index, category_counts.values)\n","plt.xlabel('Category')\n","plt.ylabel('Number of Headlines')\n","plt.title('Histogram of Headlines by Category')\n","plt.xticks(rotation=90)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"6mR6vfn3uE9N"},"source":["Prepareu i preprocesseu les dades per a l'entrenament. Farem servir one-hot encoding per les etiquetes."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"-9egBY1Wc9yD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687097367848,"user_tz":-120,"elapsed":1690,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"d38fa161-bda4-4fbc-ca57-2743c35ff293"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sklearn\n","  Downloading sklearn-0.0.post5.tar.gz (3.7 kB)\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n"]}],"source":["!pip install sklearn"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ga20obq5uE9N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687097378565,"user_tz":-120,"elapsed":229,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"0dbf7f41-d3b0-4911-9caf-46877be6cccc"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 1. 0. 0.]\n"," [0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0.]\n"," ...\n"," [0. 0. 0. 0. 1.]\n"," [0. 0. 0. 1. 0.]\n"," [1. 0. 0. 0. 0.]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]}],"source":["\n","\n","#############################################\n","# SOLUCIÓ                                #\n","#############################################\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","\n","values = df_selected[\"category\"].values\n","\n","# Instantiate the LabelEncoder object\n","label_encoder = LabelEncoder()\n","# Apply label encoding to transform the text labels into encoded integer values\n","int_encoded = label_encoder.fit_transform(values)\n","\n","# Instantiate the OneHotEncoder object\n","onehot_encoder = OneHotEncoder(sparse=False)\n","# Reshape the integer_encoded array to have shape (n, 1) where n is the number of elements\n","int_encoded = int_encoded.reshape(len(int_encoded), 1)\n","# Apply one-hot encoding to the int_encoded array to get the one-hot representation of the labels\n","onehot_encoded = onehot_encoder.fit_transform(int_encoded)\n","# Show the one-hot representation of the categorical labels\n","# Each row represents a label, and each column indicates the presence or absence of a specific category\n","print(onehot_encoded)\n"]},{"cell_type":"markdown","metadata":{"id":"OGh2TR3huE9N"},"source":["## 2.2 Preparar dades i embeddings per entrenar (1 punt)\n","La idea del model de classificació que volem implementar és més simple que la de l'encoder-decoder usat a l'apartat 1.\n","\n","El model ha de consistir només a:\n","\n","- una capa embedding amb els pesos del model Glove preentrenat per a l'anglès disponible a l'arxiu 'glove.42B.300d.txt'\n","- una capa LSTM amb un nombre d'units a escollir (per exemple, 300)\n","- una capa Doneu-vos amb una dimensió de sortida que té el nombre de categories amb les quals volem classificar (en aquest cas, 6).\n","- A més, com els function `loss` utilitzarem 'categorical_crossentropy' i com `optimizer`, 'adam'."]},{"cell_type":"markdown","metadata":{"id":"ZxxuaTTdawqX"},"source":["Primerament creem un tokenitzador per a les frases del classificador"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"kT12lHMJuE9O","executionInfo":{"status":"ok","timestamp":1687097431341,"user_tz":-120,"elapsed":222,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}}},"outputs":[],"source":["#############################################\n","# SOLUCIÓ                              #\n","#############################################\n","from keras.preprocessing.text import Tokenizer\n","\n","tokenizer = Tokenizer()\n","eng_tokenizer.fit_on_texts(df_selected[\"headline\"])"]},{"cell_type":"markdown","metadata":{"id":"THxcbzAWuE9J"},"source":["Carreguem el model GloVe següent per a l'anglès. Ho hem utilitzat a la part 1."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"WN5BNSvPuE9J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687097581453,"user_tz":-120,"elapsed":142579,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"b9fdba15-22a5-4d58-bdfd-76304bbaf77d"},"outputs":[{"output_type":"stream","name":"stdout","text":["1917494\n"]}],"source":["#############################################\n","# SOLUCIÓN                                #\n","#############################################\n","import numpy as np\n","\n","embeddings_index = {}\n","try:\n","  f = open('glove.42B.300d.txt')\n","except:\n","  f = open('/content/drive/MyDrive/glove.42B.300d.txt')\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","f.close()\n","\n","print(len(embeddings_index))\n"]},{"cell_type":"markdown","metadata":{"id":"jg47gNQ2a9mZ"},"source":["Un cop carregat el model de GloVe definim la capa d'Embedding amb tots els pesos"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"hXZn_3I9uE9O","executionInfo":{"status":"ok","timestamp":1687097653024,"user_tz":-120,"elapsed":227,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}}},"outputs":[],"source":["#############################################\n","# SOLUCIÓN                                  #\n","#############################################\n","embedding_matrix = np.zeros((len(eng_tokenizer.word_index) + 1, 300))\n","for word, i in eng_tokenizer.word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector\n","\n","embedding_layer = Embedding(len(eng_tokenizer.word_index) + 1,\n","                            embed_vec_length,\n","                            weights=[embedding_matrix],\n","                            input_length=max_text_len,\n","                            trainable=False,\n","                            mask_zero=True)\n"]},{"cell_type":"markdown","metadata":{"id":"htUhNzKzbHcZ"},"source":["Preparem el corpus d'entrenament i test, usant el model_selection de sklearn, i l'onehot_encoded per a les classes. Fem servir 80% per train."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"NAba-FJvuE9O","executionInfo":{"status":"ok","timestamp":1687097657973,"user_tz":-120,"elapsed":206,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}}},"outputs":[],"source":["#############################################\n","# SOLUCIÓ                                  #\n","#############################################\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test  = train_test_split(\n","        df_selected[\"headline\"],\n","        onehot_encoded,\n","        train_size=0.80,\n","        random_state=4231)"]},{"cell_type":"markdown","metadata":{"id":"NHwpK4hHgXwd"},"source":["Codificar els vectors d'entrada pel train i el text"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"0HUX66RmuE9P","executionInfo":{"status":"ok","timestamp":1687097665385,"user_tz":-120,"elapsed":583,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}}},"outputs":[],"source":["#############################################\n","# SOLUCIÓ                                  #\n","#############################################\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","def encode_sequences(tokenizer, length, lines):\n","    seq = tokenizer.texts_to_sequences(lines)\n","    seq = pad_sequences(seq, maxlen=length, padding='post')\n","    return seq\n","\n","\n","max_text_length = 4\n","trainX = encode_sequences(eng_tokenizer, max_text_length, X_train)\n","testX = encode_sequences(eng_tokenizer, max_text_length, X_test)"]},{"cell_type":"markdown","metadata":{"id":"r_eqWNzNgi4e"},"source":["## 2.3 Definir el model i entrenar (1 punt).\n","\n","\n","El model ha de consistir només a:\n","\n","+ una capa embedding amb els pesos del model GloVe preentrenat per a l'anglès disponible a l'arxiu 'glove.42B.300d.txt'\n","+ una capa LSTM amb un nombre d'units a escollir (per exemple, 300)\n","+ una capa Doneu-vos amb una dimensió de sortida que té el nombre de categories amb què volem classificar (en aquest cas, 6).\n","\n","A més, com els function loss utilitzarem 'categorical_crossentropy' i com a optimizer, 'adam'."]},{"cell_type":"code","execution_count":32,"metadata":{"id":"0f-2I-K4uE9P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687097674184,"user_tz":-120,"elapsed":1698,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"ac996d1a-15c3-4b73-acab-a6d59b72981a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, 4, 300)            3090600   \n","                                                                 \n"," lstm_4 (LSTM)               (None, 300)               721200    \n","                                                                 \n"," dense_2 (Dense)             (None, 5)                 1505      \n","                                                                 \n","=================================================================\n","Total params: 3,813,305\n","Trainable params: 722,705\n","Non-trainable params: 3,090,600\n","_________________________________________________________________\n","None\n"]}],"source":["#############################################\n","# SOLUCIÓN                                  #\n","#############################################\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Embedding\n","\n","out_label_size = 5\n","units = 300\n","\n","def define_model(embedding_layer, units, out_label_size):\n","    modelx = Sequential()\n","    modelx.add(embedding_layer)\n","    modelx.add(LSTM(units))\n","    modelx.add(Dense(out_label_size, activation='softmax'))\n","    return modelx\n","\n","modelx = define_model(embedding_layer, units, out_label_size)\n","print(modelx.summary())\n"]},{"cell_type":"markdown","metadata":{"id":"kpsPz5uDuZzV"},"source":["Compilar el model"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"UC9BvysEuE9Q","executionInfo":{"status":"ok","timestamp":1687097678545,"user_tz":-120,"elapsed":225,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}}},"outputs":[],"source":["#############################################\n","# SOLUCIÓ                                  #\n","#############################################\n","\n","modelx.compile(optimizer='adam', loss='categorical_crossentropy')"]},{"cell_type":"markdown","metadata":{"id":"ILf77Jy9ub5Z"},"source":["Entrenar i desar el model. En aquesta secció encara que sigui recomanable fer servir GPU, amb CPU també es pot obtenir el resultat sense haver d'esperar \"molt\" temps"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"0a5ez12buE9Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687097689537,"user_tz":-120,"elapsed":9068,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"0b06b7eb-2971-483e-a45f-119585b343a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","20/20 [==============================] - 7s 74ms/step - loss: 1.6514 - val_loss: 1.6219\n","Epoch 2/10\n","20/20 [==============================] - 0s 7ms/step - loss: 1.4766 - val_loss: 1.6677\n","Epoch 3/10\n","20/20 [==============================] - 0s 8ms/step - loss: 1.3359 - val_loss: 1.7128\n","Epoch 4/10\n","20/20 [==============================] - 0s 8ms/step - loss: 1.1497 - val_loss: 1.9493\n","Epoch 5/10\n","20/20 [==============================] - 0s 8ms/step - loss: 0.9376 - val_loss: 2.1893\n","Epoch 6/10\n","20/20 [==============================] - 0s 8ms/step - loss: 0.7554 - val_loss: 2.4835\n","Epoch 7/10\n","20/20 [==============================] - 0s 8ms/step - loss: 0.5710 - val_loss: 2.4463\n","Epoch 8/10\n","20/20 [==============================] - 0s 9ms/step - loss: 0.3853 - val_loss: 3.0432\n","Epoch 9/10\n","20/20 [==============================] - 0s 8ms/step - loss: 0.2825 - val_loss: 3.2486\n","Epoch 10/10\n","20/20 [==============================] - 0s 8ms/step - loss: 0.1922 - val_loss: 3.7326\n"]}],"source":["#############################################\n","# SOLUCIÓ                                 #\n","#############################################\n","history = modelx.fit(trainX, onehot_encoded, epochs=10, batch_size=32, validation_split=0.2)\n","\n","modelx.save('model.h5')"]},{"cell_type":"markdown","metadata":{"id":"zxKAcYjTurx2"},"source":["## 2.4 Avaluar el model (1 punt)\n","\n","S'avalua el model i se n'obtenen les diferents mètriques."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"EvXKuDAcuE9Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687097697170,"user_tz":-120,"elapsed":1903,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"d04004ce-3cd1-4f76-d005-77b7d6c224a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["7/7 [==============================] - 1s 6ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.16      0.21      0.18        33\n","           1       0.17      0.12      0.14        41\n","           2       0.14      0.11      0.12        45\n","           3       0.19      0.16      0.17        37\n","           4       0.22      0.30      0.25        44\n","\n","    accuracy                           0.18       200\n","   macro avg       0.18      0.18      0.18       200\n","weighted avg       0.18      0.18      0.17       200\n","\n"]}],"source":["#############################################\n","# SOLUCIÓ                                  #\n","#############################################\n","from numpy import argmax\n","from sklearn import metrics\n","\n","# Evaluació del model\n","preds=np.argmax(modelx.predict(testX.reshape((testX.shape[0],testX.shape[1]))), axis=-1)\n","\n","# Obtenim mètriques\n","print(metrics.classification_report(list(map(lambda x: argmax(x), y_test)), preds))"]},{"cell_type":"markdown","metadata":{"id":"Q6BDFdI_RaaS"},"source":["<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\"> Què passaria si el model de classificació l'entrenéssim amb més dades? Estem escollint només els 1000 primers, en són molt pocs exemples i s'entrena super ràpid. Què passaria amb 5000? i 10000?\n","I si no fem servir els embeddings de GloVe? Què ens aporten totes dues coses?\n","Si fem servir més dades, Cal fer servir els embeddings?\n","\n","Expressar la vostra opinió amb l'experimentació d'acord per obtenir-ne les conclusions.\n","\n","**RESPOSTA:**\n","\n","**Si l'entrenem amb més dades**, es probable que se'n millorin els resultats, incrementant els efectes beneficiosos:\n","\n","1- Millora de la capacitat de generalització: Amb més dades, el model té accés a una major diversitat de exemples, el que li permet aprendre patrons més representatius i generalitzar millor als nous exemples.\n","\n","2- Reducció de l'efecte del sobreajustament: Amb un conjunt de dades més gran, el model té més oportunitats per aprendre patrons significatius sense centrar-se excessivament en detalls específics de les mostres individuals. Això ajuda a evitar l'overfitting o sobreajustament, es a dir, quan el model s'adapta massa als detalls del conjunt de dades d'entrenament i no generalitza bé als nous exemples.\n","\n","3- Millora de la robustesa: Amb més dades, el model pot exposar-se a una major varietat de casos límit o atípics, el que el fa més robust i capaç de gestionar millor situacions inesperades o difícils.\n","\n","Per altre banda, aquest augment de dades d'entrenament pot implicar un augment en els requeriments computacionals i de temps d'entrenament del model.\n","\n","**Estem escollint només els 1000 primers, en són molt pocs exemples i s'entrena super ràpid. Què passaria amb 5000? i 10000?**\n","\n","Augmentar el nombre d'exemples d'entrenament a 5000 o 10000 pot proporcionar una millora en el rendiment del model, però també pot incrementar el temps d'entrenament i requerir ajustos en la complexitat del model. Per tant, caldria trobar un equilibri entre la disponibilitat de dades, els recursos computacionals i les necessitats de rendiment del model.\n","\n","\n","**I si no fem servir els embeddings de GloVe?**\n","\n","Si no fem servir els embeddings preentrenats de GloVe i, en canvi, inicialitzem els pesos de la capa d'embedding aleatòriament, podria passar:\n","\n","1- Rendiment inicial més baix: Els embeddings preentrenats de GloVe estan entrenats en grans quantitats de dades. Això significa que capturen relacions semàntiques i patrons de paraules que són útils per a diverses tasques de processament del llenguatge natural. Si inicialitzem els pesos de l'embedding de manera aleatòria, el model haurà de començar l'aprenentatge des de zero i, en conseqüència, pot obtenir un rendiment inicial més baix fins que aprengui representacions adequades.\n","\n","2- Més temps d'entrenament: Sense els embeddings preentrenats, el model haurà de treballar més per aprendre representacions útils de les paraules a partir de les dades d'entrenament. Això pot requerir més temps d'entrenament perquè el model ajusti els pesos de l'embedding i adquireixi una comprensió adequada del llenguatge.\n","\n","3- Depenència de les dades d'entrenament: Quan inicialitzem els pesos de l'embedding aleatòriament, el rendiment del model dependrà en gran mesura de la qualitat i la quantitat de les dades d'entrenament disponibles. Si les dades d'entrenament són limitades o no són representatives del problema, és possible que el model no pugui aprendre representacions òptimes de les paraules i, per tant, obtindrà un rendiment més baix.\n","\n","Tot i això, amb suficients dades d'entrenament i un temps d'entrenament adequat, un model amb embeddings inicialitzats aleatòriament pot aprendre representacions útils i obtenir un bon rendiment en tasques de processament del llenguatge natural.\n","\n","**Si fem servir més dades, Cal fer servir els embeddings?**\n","\n","No necessàriament cal fer servir els embeddings si afegim més dades a l'entrenament del model. L'ús d'embeddings preentrenats pot ser beneficiós quan tenim una quantitat limitada de dades d'entrenament, ja que aquests embeddings capturen coneixement i relacions semàntiques extretes d'un gran corpus. No obstant això, si tenim un conjunt de dades d'entrenament més gran, podríem obtenir resultats satisfactoris sense necessitat d'utilitzar embeddings preentrenats.\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gpRSYwVIwqZ1"},"source":["# PART 3\n"]},{"cell_type":"markdown","metadata":{"id":"je-AFXAsuE9R"},"source":["# 3. Detecció de NER and NEL (2 punts)"]},{"cell_type":"markdown","metadata":{"id":"wc5mcU77gWpe"},"source":["En aquesta part detectarem entitats numerades utilitzant tant SpaCy amb transformers com transformers simplement. En el segon cas usant una llibreria anomenada simple transformers.\n","\n","D'altra banda, també farem Named Entity Linking (NEL) on cercarem entitats linkades a una base de coneixement (KB), en aquest cas DBpedia. Trobarem els enllaços a Wikpedia de certes entitats del text, utilitzant DBPedia Spotlight."]},{"cell_type":"markdown","metadata":{"id":"iGB1-kYNxW5V"},"source":["## 3.1 Detecció de NER a Spacy (1 punt)"]},{"cell_type":"markdown","metadata":{"id":"SIAzOTIEiH5I"},"source":["Detecció d'entitats nomenades (NER) usant spaCy. En aquesta secció farem servir SpaCy per detectar NER. A partir d'un corpus de CONLL 2003, el reentrenarem i així afinarem la seva cobertura per a aquestes classes."]},{"cell_type":"markdown","metadata":{"id":"Qn9KhNzWlgjx"},"source":["Instal·lem spacy i fem models de llenguatge que necessitem."]},{"cell_type":"code","execution_count":36,"metadata":{"id":"6j5WkL16iH5Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687097954193,"user_tz":-120,"elapsed":30788,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"3eecfbfd-e75b-490a-d5d8-e7a1fd5996a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy==3.2.0\n","  Downloading spacy-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (1.0.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (1.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (2.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (3.0.8)\n","Collecting thinc<8.1.0,>=8.0.12 (from spacy==3.2.0)\n","  Downloading thinc-8.0.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (659 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (0.7.9)\n","Collecting wasabi<1.1.0,>=0.8.1 (from spacy==3.2.0)\n","  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (2.4.6)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (2.0.8)\n","Collecting typer<0.5.0,>=0.3.0 (from spacy==3.2.0)\n","  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (0.10.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (4.65.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (1.22.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (2.27.1)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 (from spacy==3.2.0)\n","  Downloading pydantic-1.8.2-py3-none-any.whl (126 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (23.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (3.3.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy==3.2.0) (6.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy==3.2.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (3.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.2.0) (2.1.2)\n","Installing collected packages: wasabi, typer, pydantic, thinc, spacy\n","  Attempting uninstall: wasabi\n","    Found existing installation: wasabi 1.1.1\n","    Uninstalling wasabi-1.1.1:\n","      Successfully uninstalled wasabi-1.1.1\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.7.0\n","    Uninstalling typer-0.7.0:\n","      Successfully uninstalled typer-0.7.0\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.10.7\n","    Uninstalling pydantic-1.10.7:\n","      Successfully uninstalled pydantic-1.10.7\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.9\n","    Uninstalling thinc-8.1.9:\n","      Successfully uninstalled thinc-8.1.9\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.5.2\n","    Uninstalling spacy-3.5.2:\n","      Successfully uninstalled spacy-3.5.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","en-core-web-sm 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.2.0 which is incompatible.\n","inflect 6.0.4 requires pydantic>=1.9.1, but you have pydantic 1.8.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pydantic-1.8.2 spacy-3.2.0 thinc-8.0.17 typer-0.4.2 wasabi-0.10.1\n","2023-06-18 14:19:03.353770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl#egg=en_core_web_sm==3.2.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-sm==3.2.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.2.0) (3.2.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.17)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.9)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.10.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.6)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.8)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.2)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.10.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.65.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.22.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.27.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (23.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (6.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.1.2)\n","Installing collected packages: en-core-web-sm\n","  Attempting uninstall: en-core-web-sm\n","    Found existing installation: en-core-web-sm 3.5.0\n","    Uninstalling en-core-web-sm-3.5.0:\n","      Successfully uninstalled en-core-web-sm-3.5.0\n","Successfully installed en-core-web-sm-3.2.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n"]}],"source":["!pip install spacy==3.2.0\n","\n","!python -m spacy download en_core_web_sm-3.2.0 --direct"]},{"cell_type":"markdown","metadata":{"id":"ttkg0CqW4Ym9"},"source":["Definim un parell de funcions que ens permetrà imprimir els resultats de la detecció de NER de forma molt interpretable"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"O8Ot3tH3lO48","executionInfo":{"status":"ok","timestamp":1687098128782,"user_tz":-120,"elapsed":3,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}}},"outputs":[],"source":["def get_tokens_to_print(model, text):\n","  \"\"\"Print tokens of the text and its relevant attributes.\n","\n","    Parameters:\n","      model (spaCy model): spaCy model used for tokenization\n","      text (str):  text to transform in a spaCy doc class.\n","\n","    Returns: ---\n","  \"\"\"\n","  doc = model(text)\n","  print (f\"The text:\\n\\n{get_text_to_print(text)}\\n\\nwas converted in a spaCy object: {type(doc)}\\n\")\n","  print (f\"Token-based analysis. Each token is a spaCy object: {type(doc[0])}\\n\")\n","\n","  # We obtain rows to print: headers and content\n","  rows  = []\n","  # head_align: List of tuples. Each tuple: heather and its alignment when printing\n","  head_align  = [('Token', '<'), ('Lemma', '<'), ('Syntactic parent', '<'), ('#Tok', '>'), ('Chr_Start', '>'), ('Chr_End', '>'), ('POS', '<'),\n","                 ('TAG', '<'), ('TAG meaning:', '<'), ('ENT', '<'), ('DEP', '<'), ('DEP meaning:', '<')]\n","  head, align = list(zip(*head_align))\n","  rows.append(head)                           # Header\n","  rows.append(['='*len(i) for i in head])     # Underline headers\n","  for tok in doc:\n","    rows.append([tok.text, tok.lemma_, tok.head.text, str(tok.i), str(tok.idx), str(tok.idx+len(tok)-1), tok.pos_,\n","                 tok.tag_, str(spacy.explain(tok.tag_))[:20], tok.ent_type_, tok.dep_, str(spacy.explain(tok.dep_))[:20]])\n","\n","  # Width of each column: the witdh of the longest element\n","  columns       = zip(*rows)\n","  column_widths = [max(len(i) for i in col) for col in columns]\n","\n","  # Print the files with alignment\n","  for row in rows:\n","    print(*[f\"{row[i]:{align[i]}{column_widths[i]}}  \" for i in range(0, len(row))])"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"u9N8mQA3s56Z","executionInfo":{"status":"ok","timestamp":1687098133432,"user_tz":-120,"elapsed":253,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}}},"outputs":[],"source":["def get_text_to_print(text):\n","  \"\"\"Format given text.\n","\n","    Parameters:\n","      text (str): text to print\n","\n","    Returns:\n","      str: text formatted in 100 character lines with an initial line numbering the characters\n","  \"\"\"\n","  line_length = 100\n","  line_poss   = \"     1-------10--------20--------30--------40--------50--------60--------70--------80--------90-------100\"\n","  text        = text.replace(\"\\n\", \" \")     # In order to avoid that the \\n character produces a line change.\n","  text        = text.replace(\"\\r\", \" \")     # In wikipedia texts we have detected the character '\\r' that, if interpreted, may induce some printing problems.\n","  text_format = \"\\n\".join([ f\"{i//line_length:<5}{text[i:i+line_length]}\"  for i in range(0, len(text), line_length) ])\n","  return line_poss + \"\\n\" + text_format + \"\\n\" + line_poss"]},{"cell_type":"markdown","metadata":{"id":"w2xbabYm4uIe"},"source":["Carreguem el model \"en_core_web_sm\""]},{"cell_type":"code","execution_count":39,"metadata":{"id":"WNY5YFsUlYBN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687098150895,"user_tz":-120,"elapsed":3796,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"9688b2df-595d-40da-c6ec-1550327ddd72"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model carregat: 'en_core_web_sm'  loaded correctly!\n"]}],"source":["#\n","##################\n","## SOLUCIO ####\n","##################\n","\n","import spacy\n","MODEL = \"en_core_web_sm\"\n","nlp_md = spacy.load(MODEL)\n","print (f\"Model carregat: '{MODEL}'  loaded correctly!\")"]},{"cell_type":"markdown","metadata":{"id":"5GCpZoQd4oqD"},"source":["Convertim un text en objecte 'Doc' de spaCy i visualitzem els resultats d'analitzar aquest text a nivell de POS, NER, ENT, DEP..."]},{"cell_type":"code","execution_count":40,"metadata":{"id":"iIDs4LbelUjj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687098158375,"user_tz":-120,"elapsed":222,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"7c6ade13-3df3-4943-ba94-58fb4d6ed80a"},"outputs":[{"output_type":"stream","name":"stdout","text":["The text:\n","\n","     1-------10--------20--------30--------40--------50--------60--------70--------80--------90-------100\n","0    True happiness comes from the joy of deeds well done, the zest of creating things new\n","     1-------10--------20--------30--------40--------50--------60--------70--------80--------90-------100\n","\n","was converted in a spaCy object: <class 'spacy.tokens.doc.Doc'>\n","\n","Token-based analysis. Each token is a spaCy object: <class 'spacy.tokens.token.Token'>\n","\n","Token       Lemma       Syntactic parent   #Tok   Chr_Start   Chr_End   POS     TAG   TAG meaning:           ENT   DEP      DEP meaning:          \n","=====       =====       ================   ====   =========   =======   ===     ===   ============           ===   ===      ============          \n","True        true        happiness             0           0         3   ADJ     JJ    adjective (English),         amod     adjectival modifier   \n","happiness   happiness   comes                 1           5        13   NOUN    NN    noun, singular or ma         nsubj    nominal subject       \n","comes       come        comes                 2          15        19   VERB    VBZ   verb, 3rd person sin         ROOT     None                  \n","from        from        comes                 3          21        24   ADP     IN    conjunction, subordi         prep     prepositional modifi  \n","the         the         joy                   4          26        28   DET     DT    determiner                   det      determiner            \n","joy         joy         from                  5          30        32   NOUN    NN    noun, singular or ma         pobj     object of prepositio  \n","of          of          joy                   6          34        35   ADP     IN    conjunction, subordi         prep     prepositional modifi  \n","deeds       deed        of                    7          37        41   NOUN    NNS   noun, plural                 pobj     object of prepositio  \n","well        well        done                  8          43        46   ADV     RB    adverb                       advmod   adverbial modifier    \n","done        do          comes                 9          48        51   VERB    VBN   verb, past participl         advcl    adverbial clause mod  \n",",           ,           done                 10          52        52   PUNCT   ,     punctuation mark, co         punct    punctuation           \n","the         the         zest                 11          54        56   DET     DT    determiner                   det      determiner            \n","zest        zest        happiness            12          58        61   NOUN    NN    noun, singular or ma         appos    appositional modifie  \n","of          of          zest                 13          63        64   ADP     IN    conjunction, subordi         prep     prepositional modifi  \n","creating    create      of                   14          66        73   VERB    VBG   verb, gerund or pres         pcomp    complement of prepos  \n","things      thing       creating             15          75        80   NOUN    NNS   noun, plural                 dobj     direct object         \n","new         new         creating             16          82        84   ADJ     JJ    adjective (English),         advmod   adverbial modifier    \n"]}],"source":["##################\n","## SOLUCIO ####\n","##################\n","\n","# Convertir un text en objecte 'Doc' de spaCy\n","text = \"True happiness comes from the joy of deeds well done, the zest of creating things new\"\n","\n","get_tokens_to_print(nlp_md, text)"]},{"cell_type":"markdown","metadata":{"id":"IHr-Nz6czi3P"},"source":["Entrenar un nou model de NER amb les dades de CONLL2003"]},{"cell_type":"markdown","metadata":{"id":"8BHEexwQ2K5f"},"source":["Convertim els fitxers conll03 (train i valid) a format spaCy.\n","El corpus l'hem obtingut d'aquí:\n","https://github.com/Hironsan/anago\n","\n","Tip: spacy conté funcions que permeten convertir de format conll al format compilat que necessiten el mòdul de train de spaCy."]},{"cell_type":"code","execution_count":41,"metadata":{"id":"nYfj6_LVziVV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687098208648,"user_tz":-120,"elapsed":35597,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"3a5c5896-a76b-4757-dd9c-f4c4fc2d49e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-18 14:22:57.267283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n","\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n","into documents with `-n 10`.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (14041 documents):\n","/content/drive/MyDrive/ner/conll03/train.spacy\u001b[0m\n","2023-06-18 14:23:22.404632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n","\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n","into documents with `-n 10`.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (3250 documents):\n","/content/drive/MyDrive/ner/conll03/valid.spacy\u001b[0m\n"]}],"source":["#####################\n","### SOLUCIO ###\n","##################\n","!python -m spacy convert /content/drive/MyDrive/ner/conll03/train.txt -c conll /content/drive/MyDrive/ner/conll03/\n","!python -m spacy convert /content/drive/MyDrive/ner/conll03/valid.txt -c conll /content/drive/MyDrive/ner/conll03/\n"]},{"cell_type":"markdown","metadata":{"id":"zdXR3Jvg5kQV"},"source":["Descarregar el model 'en_core_web_trf'"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"CArCJmMSKm0H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687098276065,"user_tz":-120,"elapsed":43529,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"f649f27c-0e3a-4d5b-d93c-e14d057c11c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-18 14:23:56.756168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.2.0/en_core_web_trf-3.2.0-py3-none-any.whl#egg=en_core_web_trf==3.2.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-trf==3.2.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.2.0/en_core_web_trf-3.2.0-py3-none-any.whl (460.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.2/460.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-trf==3.2.0) (3.2.0)\n","Collecting spacy-transformers<1.2.0,>=1.1.2 (from en-core-web-trf==3.2.0)\n","  Downloading spacy_transformers-1.1.9-py2.py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (1.0.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (1.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (2.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (3.0.8)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (8.0.17)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (0.7.9)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (0.10.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (2.4.6)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (2.0.8)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (0.4.2)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (0.10.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (4.65.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (1.22.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (2.27.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (1.8.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (23.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (3.3.0)\n","INFO: pip is looking at multiple versions of spacy-transformers to determine which version is compatible with other requirements. This could take a while.\n","  Downloading spacy_transformers-1.1.8-py2.py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading spacy_transformers-1.1.7-py2.py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers<4.21.0,>=3.4.0 (from spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0)\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0) (2.0.1+cu118)\n","Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0)\n","  Downloading spacy_alignments-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (6.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (3.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0) (3.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0) (16.0.5)\n","Collecting huggingface-hub<1.0,>=0.1.0 (from transformers<4.21.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.21.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.21.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers<4.21.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0)\n","  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-trf==3.2.0) (2.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers<4.21.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0) (2023.4.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.2.0) (1.3.0)\n","Installing collected packages: tokenizers, spacy-alignments, huggingface-hub, transformers, spacy-transformers, en-core-web-trf\n","Successfully installed en-core-web-trf-3.2.0 huggingface-hub-0.15.1 spacy-alignments-0.9.0 spacy-transformers-1.1.7 tokenizers-0.12.1 transformers-4.20.1\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_trf')\n"]}],"source":["!python -m spacy download en_core_web_trf"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"AKBnk2lcKlWZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687102151324,"user_tz":-120,"elapsed":8000,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"3e9dca13-bbc2-40ca-e3ff-019081335384"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-18 15:29:08.110764: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n","\u001b[1m\n","================= Installed pipeline packages (spaCy v3.2.0) =================\u001b[0m\n","\u001b[38;5;4mℹ spaCy installation: /usr/local/lib/python3.10/dist-packages/spacy\u001b[0m\n","\n","NAME              SPACY            VERSION                            \n","en_core_web_trf   >=3.2.0,<3.3.0   \u001b[38;5;2m3.2.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n","en_core_web_sm    >=3.2.0,<3.3.0   \u001b[38;5;2m3.2.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n","\n"]}],"source":["!python -m spacy validate"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"NAA9QpGWKosp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687102154472,"user_tz":-120,"elapsed":206,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"4ef06a1e-7ea6-43bf-b5f2-f0807697d8ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Spacy version installed: 3.2.0\n"]}],"source":["import spacy\n","print (f\"Spacy version installed: {spacy.__version__}\")"]},{"cell_type":"markdown","metadata":{"id":"L35Q-Df_5yfC"},"source":["Entrenar usant la funció train de spaCy a partir del model 'en_core_web_trf'.\n","Usar el fitxer de configuració adjunt i modificar les coses que considereu oportunes. La versió lliurada ja funciona però es pot customitzar si hi ha interès. '"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iXl4T4595d1x","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6da0b1bf-bade-4f12-f41d-25da056bafcc"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-18 14:26:09.599379: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[38;5;2m✔ Created output directory: /content/drive/MyDrive/tmp/output3\u001b[0m\n","\u001b[38;5;4mℹ Saving to output directory: /content/drive/MyDrive/tmp/output3\u001b[0m\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2023-06-18 14:26:27,675] [INFO] Set up nlp object from config\n","[2023-06-18 14:26:27,699] [INFO] Pipeline: ['transformer', 'ner']\n","[2023-06-18 14:26:27,699] [INFO] Resuming training for: ['ner', 'transformer']\n","[2023-06-18 14:26:27,706] [INFO] Created vocabulary\n","[2023-06-18 14:26:31,992] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_trf) has no vectors. This is almost certainly a mistake.\n","[2023-06-18 14:26:31,994] [INFO] Added vectors: en_core_web_trf\n","[2023-06-18 14:26:32,026] [INFO] Finished initializing nlp object\n","[2023-06-18 14:26:32,026] [INFO] Initialized pipeline components: []\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  --------  ------  ------  ------  ------\n","  0       0         482.58    344.43    7.88    6.40   10.27    0.08\n","  1     200       48177.82  26309.27   52.28   54.14   50.54    0.52\n","  2     400        4090.56  11722.01   70.39   70.43   70.35    0.70\n","  3     600        2357.03   5190.86   93.67   93.44   93.91    0.94\n","  4     800        1820.48   1998.88   94.40   94.34   94.46    0.94\n","  5    1000        1080.97   1247.99   94.89   94.78   95.00    0.95\n","  6    1200         830.11   1018.38   95.22   95.04   95.41    0.95\n","  7    1400         675.53    728.45   95.55   95.22   95.88    0.96\n","  8    1600         606.59    671.83   95.45   95.09   95.81    0.95\n","  9    1800         467.13    471.84   95.40   95.08   95.71    0.95\n"," 10    2000         404.70    479.26   95.69   95.65   95.74    0.96\n"," 12    2200         449.48    423.60   95.39   94.99   95.79    0.95\n"," 13    2400         357.61    376.68   95.47   95.33   95.61    0.95\n"]}],"source":["##################\n","### SOLUCIO ###\n","################\n","import subprocess\n","import os\n","\n","# Load the training data and validation data in CoNLL format\n","train_data = \"/content/drive/MyDrive/ner/conll03/train.txt\"\n","dev_data = \"/content/drive/MyDrive/ner/conll03/valid.txt\"\n","\n","# Specify the path to the configuration file\n","config_path = \"/content/drive/MyDrive/ner/conll03/config.cfg\"\n","\n","# model path\n","model_path = '/content/drive/MyDrive/tmp/output2/model-last/'\n","\n","#!python -m spacy train {config_path} --output /content/drive/MyDrive/tmp/output --paths.train {train_data} --paths.dev {dev_data}\n","\n","# !python -m spacy train     Executem el mòdul 'spacy' en mode entrenament\n","# config_path    Conté la configuració per l'entrenament del model\n","# --output /content/drive/MyDrive/tmp/output/     Ruta de sortida on es guarden els resultats i els models entrenats\n","# --paths.train /content/drive/MyDrive/ner/conll03/train.spacy    ruta de l'arxiu d'entrenament 'train.spacy' que conté les dades d'entrenament en format spacy\n","# Mira si el model està ja entrenat i si no ho està entrena (es fa amb un try ja que si el model no està al directori adequat el programa s'abortaria)\n","if not os.path.exists(model_path):\n","  !python -m spacy train /content/drive/MyDrive/ner/conll03/config.cfg --output /content/drive/MyDrive/tmp/output2/ --paths.train /content/drive/MyDrive/ner/conll03/train.spacy  --gpu-id 0 --paths.dev /content/drive/MyDrive/ner/conll03/valid.spacy"]},{"cell_type":"markdown","metadata":{"id":"fOlpHvLn6Qfg"},"source":["Predir una frase d'exemple amb el nou model i visualitzar-ne els resultats.\n","Compte que col·lab, no li agrada carregar models des de paths, només si estan en local, de manera que recomanem, generar el model en drive, guardar-los i després pujar la millor versió per carregar-los des d'aquí."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"rmr1vYmY_MUC","executionInfo":{"status":"ok","timestamp":1687102192588,"user_tz":-120,"elapsed":6377,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"7171850b-3e66-4a26-e0d0-5be82dab00c9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Barack Obama\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n","</mark>\n"," worked in \n","<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    New York\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n","</mark>\n","</div></span>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Barack Obama PER\n","New York LOC\n"]}],"source":["\n","##################\n","### SOLUCIO ###\n","################\n","import spacy_transformers\n","\n","nlp_predict= spacy.load(\"/content/drive/MyDrive/tmp/output2/model-last/\")\n","\n","text = \"Barack Obama worked in New York\"\n","doc = nlp_predict(text)\n","spacy.displacy.render(doc, style=\"ent\", jupyter=True)\n","\n","for ent in doc.ents:\n","    print(ent.text, ent.label_)"]},{"cell_type":"markdown","metadata":{"id":"8TR08_0r7dIT"},"source":["Avaluar els resultats obtinguts i calcular les mètriques"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"cJqZUm9k7gNb","executionInfo":{"status":"ok","timestamp":1687102277281,"user_tz":-120,"elapsed":30630,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ddfda543-b513-44d5-adee-0a7ca3dae9c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-18 15:30:51.173520: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n","\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n","into documents with `-n 10`.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (3453 documents):\n","/content/drive/MyDrive/ner/conll03/test.spacy\u001b[0m\n","2023-06-18 15:31:03.293433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.10/dist-packages/spacy/__main__.py\", line 4, in <module>\n","    setup_cli()\n","  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/_util.py\", line 71, in setup_cli\n","    command(prog_name=COMMAND)\n","  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1130, in __call__\n","    return self.main(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1055, in main\n","    rv = self.invoke(ctx)\n","  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1657, in invoke\n","    return _process_result(sub_ctx.command.invoke(sub_ctx))\n","  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1404, in invoke\n","    return ctx.invoke(self.callback, **ctx.params)\n","  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 760, in invoke\n","    return __callback(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 532, in wrapper\n","    return callback(**use_params)  # type: ignore\n","  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 42, in evaluate_cli\n","    evaluate(\n","  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 76, in evaluate\n","    nlp = util.load_model(model)\n","  File \"/usr/local/lib/python3.10/dist-packages/spacy/util.py\", line 422, in load_model\n","    return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]\n","  File \"/usr/local/lib/python3.10/dist-packages/spacy/util.py\", line 489, in load_model_from_path\n","    return nlp.from_disk(model_path, exclude=exclude, overrides=overrides)\n","  File \"/usr/local/lib/python3.10/dist-packages/spacy/language.py\", line 2043, in from_disk\n","    util.from_disk(path, deserializers, exclude)  # type: ignore[arg-type]\n","  File \"/usr/local/lib/python3.10/dist-packages/spacy/util.py\", line 1300, in from_disk\n","    reader(path / key)\n","  File \"/usr/local/lib/python3.10/dist-packages/spacy/language.py\", line 2037, in <lambda>\n","    deserializers[name] = lambda p, proc=proc: proc.from_disk(  # type: ignore[misc]\n","  File \"/usr/local/lib/python3.10/dist-packages/spacy_transformers/pipeline_component.py\", line 420, in from_disk\n","    util.from_disk(path, deserialize, exclude)\n","  File \"/usr/local/lib/python3.10/dist-packages/spacy/util.py\", line 1300, in from_disk\n","    reader(path / key)\n","  File \"/usr/local/lib/python3.10/dist-packages/spacy_transformers/pipeline_component.py\", line 393, in load_model\n","    with open(p, \"rb\") as mfile:\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/tmp/output2/model-best/transformer/model'\n"]}],"source":["############\n","###SOLUCIO##\n","##############\n","!python -m spacy convert /content/drive/MyDrive/ner/conll03/test.txt -c conll /content/drive/MyDrive/ner/conll03/\n","\n","!python -m spacy evaluate /content/drive/MyDrive/tmp/output2/model-best /content/drive/MyDrive/ner/conll03/test.spacy --gpu-id 0"]},{"cell_type":"markdown","metadata":{"id":"wPUPNSqbXT-T"},"source":["## 3.3 NEL (1 punt)"]},{"cell_type":"markdown","metadata":{"id":"itchQVx3XcU6"},"source":["En aquesta secció, la idea és obtenir els enllaços a la DBpedia spotlight relacionats amb les entitats que s'han obtingut de NER usant spaCy.\n","\n","\n","\n","Desenvolupa una funció que ha donat un text, obteniu automàticament les entitats relacionades al DBpedia Spotlight.\n","URL d'accés a l'API, DBPedia anglès: https://www.dbpedia-spotlight.org/api o https://www.dbpedia-spotlight.org/api/en"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"PKZ_bvCVXjI2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687102294890,"user_tz":-120,"elapsed":1172,"user":{"displayName":"Nuria Aguilera","userId":"08809099748322649584"}},"outputId":"f92f1422-7e26-4c06-8a79-57b24afc2ea5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Related Entities:\n","http://dbpedia.org/resource/Barack_Obama\n","http://dbpedia.org/resource/New_York_City\n"]}],"source":["##############################\n","# SOLUCIO #\n","########################\n","import requests\n","\n","def get_related_entities(text):\n","    url = \"https://api.dbpedia-spotlight.org/en/annotate\"\n","    params = {\n","        \"text\": text\n","    }\n","    headers = {\n","        \"accept\": \"application/json\"\n","    }\n","\n","    response = requests.get(url, params=params, headers=headers)\n","    if response.status_code == 200:\n","        entities = []\n","        data = response.json()\n","        resources = data[\"Resources\"]\n","        for resource in resources:\n","            entities.append(resource[\"@URI\"])\n","        return entities\n","    else:\n","        return None\n","\n","text = \"Barack Obama worked in New York\"\n","related_entities = get_related_entities(text)\n","if related_entities:\n","    print(\"Related Entities:\")\n","    for entity in related_entities:\n","        print(entity)\n","else:\n","    print(\"An error occurred during the API request.\")\n","\n"]},{"cell_type":"markdown","source":["Observem que tant en aquest darrer codi com en el model entrenat, si introduim la mateixa frase com a input, obtenim les mateixes enitats com a outputs (en el cas de la frase de mostra, ens detecta i etiqueta Barack Obama i New York)."],"metadata":{"id":"w_5bRkFAnQB4"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}