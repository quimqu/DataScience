{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84316533",
   "metadata": {
    "papermill": {
     "duration": 0.008304,
     "end_time": "2023-07-06T13:23:35.034595",
     "exception": false,
     "start_time": "2023-07-06T13:23:35.026291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CAFA 5 protein function Prediction with TensorFlow\n",
    "\n",
    "This notebook walks you through how to train a DNN model using TensorFlow on the CAFA 5 protein function Prediction dataset made available for this competition. \n",
    "\n",
    "The objective of the model is to predict the function(aka **GO term ID**) of a set of proteins based on their amino acid sequences and other data.\n",
    "\n",
    "\n",
    "**Note** : This notebook runs without any GPU. This is because enabling GPUs leaves less RAM memory on the VM and the submission step needs a lot of memory. One point where this would impact is when training the model. With CPU it will take around 2 minutes while on GPU it would take around 30 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf558e2a",
   "metadata": {
    "papermill": {
     "duration": 0.007198,
     "end_time": "2023-07-06T13:23:35.049440",
     "exception": false,
     "start_time": "2023-07-06T13:23:35.042242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## About the Data\n",
    "\n",
    "### Protein Sequence\n",
    "\n",
    "Each protein is composed of dozens or hundreds of amino acids that are linked sequentially. Each amino acid in the sequence may be represented by a one-letter or three-letter code. Thus the sequence of a protein is often notated as a string of letters. \n",
    "\n",
    "<img src=\"https://cityu-bioinformatics.netlify.app/img/tools/protein/pro_seq.png\" alt =\"Sequence.png\" style='width: 800px;' >\n",
    "\n",
    "Image source - [https://cityu-bioinformatics.netlify.app/](https://cityu-bioinformatics.netlify.app/too2/new_proteo/pro_seq/)\n",
    "\n",
    "The `train_sequences.fasta` made available for this competitions, contains the sequences for proteins with annotations (labelled proteins)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8475d4",
   "metadata": {
    "papermill": {
     "duration": 0.006876,
     "end_time": "2023-07-06T13:23:35.064219",
     "exception": false,
     "start_time": "2023-07-06T13:23:35.057343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gene Ontology\n",
    "\n",
    "We can define the functional properties of a proteins using Gene Ontology(GO). Gene Ontology (GO) describes our understanding of the biological domain with respect to three aspects:\n",
    "1. Molecular Function (MF)\n",
    "2. Biological Process (BP)\n",
    "3. Cellular Component (CC)\n",
    "\n",
    "Read more about Gene Ontology [here](http://geneontology.org/docs/ontology-documentation).\n",
    "\n",
    "File `train_terms.tsv` contains the list of annotated terms (ground truth) for the proteins in `train_sequences.fasta`. In `train_terms.tsv` the first column indicates the protein's UniProt accession ID (unique protein id), the second is the `GO Term ID`, and the third indicates in which ontology the term appears. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709fb723",
   "metadata": {
    "papermill": {
     "duration": 0.006793,
     "end_time": "2023-07-06T13:23:35.078142",
     "exception": false,
     "start_time": "2023-07-06T13:23:35.071349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Labels of the dataset\n",
    "\n",
    "The objective of our model is to predict the terms (functions) of a protein sequence. One protein sequence can have many functions and can thus be classified into any number of terms. Each term is uniquely identified by a `GO Term ID`. Thus our model has to predict all the `GO Term ID`s for a protein sequence. This means that the task at hand is a multi-label classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba3885",
   "metadata": {
    "papermill": {
     "duration": 0.006775,
     "end_time": "2023-07-06T13:23:35.092163",
     "exception": false,
     "start_time": "2023-07-06T13:23:35.085388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bde152",
   "metadata": {
    "papermill": {
     "duration": 0.006961,
     "end_time": "2023-07-06T13:23:35.106415",
     "exception": false,
     "start_time": "2023-07-06T13:23:35.099454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Protein embeddings for train and test data\n",
    "\n",
    "To train a machine learning model we cannot use the alphabetical protein sequences in`train_sequences.fasta` directly. They have to be converted into a vector format. In this notebook, we will use embeddings of the protein sequences to train the model. You can think of protein embeddings to be similar to word embeddings used to train NLP models.\n",
    "<!-- Instead, to make calculations and data preparation easier we will use precalculated protein embeddings.\n",
    " -->\n",
    "Protein embeddings are a machine-friendly method of capturing the protein's structural and functional characteristics, mainly through its sequence. One approach is to train a custom ML model to learn the protein embeddings of the protein sequences in the dataset being used in this notebook. Since this dataset represents proteins using amino-acid sequences which is a standard approach, we can use any publicly available pre-trained protein embedding models to generate the embeddings.\n",
    "\n",
    "There are a variety of protein embedding models. To make data preparation easier, we have used the precalculated protein embeddings created by [Sergei Fironov](https://www.kaggle.com/sergeifironov) using the Rost Lab's T5 protein language model in this notebook. The precalculated protein embeddings can be found [here](https://www.kaggle.com/datasets/sergeifironov/t5embeds). We have added this dataset to the notebook along with the dataset made available for the competition.\n",
    "\n",
    "To add this to your enviroment, on the right side panel, click on `Add Data` and search for `t5embeds` (make sure that it's the correct [one](https://www.kaggle.com/datasets/sergeifironov/t5embeds)) and then click on the `+` beside it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8240e6",
   "metadata": {
    "papermill": {
     "duration": 0.007097,
     "end_time": "2023-07-06T13:23:35.121412",
     "exception": false,
     "start_time": "2023-07-06T13:23:35.114315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a956c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T13:23:35.140167Z",
     "iopub.status.busy": "2023-07-06T13:23:35.139608Z",
     "iopub.status.idle": "2023-07-06T13:23:46.469865Z",
     "shell.execute_reply": "2023-07-06T13:23:46.468500Z"
    },
    "papermill": {
     "duration": 11.342899,
     "end_time": "2023-07-06T13:23:46.472796",
     "exception": false,
     "start_time": "2023-07-06T13:23:35.129897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "\n",
    "# Required for progressbar widget\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe3c5cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T13:23:46.489853Z",
     "iopub.status.busy": "2023-07-06T13:23:46.488856Z",
     "iopub.status.idle": "2023-07-06T13:23:46.494313Z",
     "shell.execute_reply": "2023-07-06T13:23:46.493430Z"
    },
    "papermill": {
     "duration": 0.016598,
     "end_time": "2023-07-06T13:23:46.496821",
     "exception": false,
     "start_time": "2023-07-06T13:23:46.480223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_model_quim = False\n",
    "load_matrices = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb519343",
   "metadata": {
    "papermill": {
     "duration": 0.006915,
     "end_time": "2023-07-06T13:23:46.511370",
     "exception": false,
     "start_time": "2023-07-06T13:23:46.504455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fc1b0f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T13:23:46.551492Z",
     "iopub.status.busy": "2023-07-06T13:23:46.550798Z",
     "iopub.status.idle": "2023-07-06T13:23:55.626442Z",
     "shell.execute_reply": "2023-07-06T13:23:55.625046Z"
    },
    "papermill": {
     "duration": 9.110547,
     "end_time": "2023-07-06T13:23:55.629075",
     "exception": false,
     "start_time": "2023-07-06T13:23:46.518528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5363863, 3)\n",
      "      EntryID        term aspect\n",
      "0  A0A009IHW8  GO:0008152    BPO\n",
      "1  A0A009IHW8  GO:0034655    BPO\n",
      "2  A0A009IHW8  GO:0072523    BPO\n",
      "3  A0A009IHW8  GO:0044270    BPO\n",
      "4  A0A009IHW8  GO:0006753    BPO\n",
      "aspect\n",
      "BPO    21285\n",
      "CCO     2957\n",
      "MFO     7224\n",
      "Name: term, dtype: int64\n",
      "number of unique GO terms: 31466\n",
      "There are no terms that appear in only one aspect\n"
     ]
    }
   ],
   "source": [
    "train_terms = pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv\",sep=\"\\t\")\n",
    "print(train_terms.shape)\n",
    "print(train_terms.head())\n",
    "\n",
    "# Count unique terms by aspect\n",
    "term_counts = train_terms.groupby('aspect')['term'].nunique()\n",
    "print(term_counts)\n",
    "\n",
    "# Group terms by aspect and count the occurrences\n",
    "term_aspect_counts = train_terms.groupby('term')['aspect'].nunique()\n",
    "print('number of unique GO terms:',len(train_terms['term'].unique()))\n",
    "\n",
    "# Filter terms that appear in only one aspect\n",
    "multiple_aspect_terms = term_aspect_counts[term_aspect_counts > 1]\n",
    "\n",
    "if multiple_aspect_terms.empty:\n",
    "    print('There are no terms that appear in only one aspect')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7adb6df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T13:23:55.647518Z",
     "iopub.status.busy": "2023-07-06T13:23:55.646454Z",
     "iopub.status.idle": "2023-07-06T13:23:59.763435Z",
     "shell.execute_reply": "2023-07-06T13:23:59.762535Z"
    },
    "papermill": {
     "duration": 4.129313,
     "end_time": "2023-07-06T13:23:59.766175",
     "exception": false,
     "start_time": "2023-07-06T13:23:55.636862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Assign unique identifiers to terms\n",
    "unique_terms = train_terms['term'].unique()\n",
    "term_to_id = {term: idx for idx, term in enumerate(unique_terms)}\n",
    "\n",
    "if not load_matrices:\n",
    "    \n",
    "    # Step 2: Create an empty dictionary to store encoded sparse matrices\n",
    "    encoded_matrices = {}\n",
    "\n",
    "    # Step 3: Iterate over EntryID groups and encode terms\n",
    "    grouped_entries = train_terms.groupby('EntryID')\n",
    "    for entry_id, group in grouped_entries:\n",
    "        # Initialize an empty sparse matrix for the EntryID group\n",
    "        num_terms = len(group)\n",
    "        encoded_matrix = sp.lil_matrix((1, len(unique_terms)), dtype=np.int8)\n",
    "\n",
    "        # Encode terms in the sparse matrix\n",
    "        for _, row in group.iterrows():\n",
    "            term = row['term']\n",
    "            term_id = term_to_id[term]\n",
    "            encoded_matrix[0, term_id] = max(encoded_matrix[0, term_id], 1)  # Using max encoding\n",
    "\n",
    "        # Store the encoded sparse matrix for the EntryID\n",
    "        encoded_matrices[entry_id] = encoded_matrix.tocsr()\n",
    "\n",
    "    # Save the encoded_matrices dictionary\n",
    "    with open('encoded_matrices.pkl', 'wb') as file:\n",
    "        pickle.dump(encoded_matrices, file)\n",
    "\n",
    "    # Example usage: Retrieve encoded matrix for a specific EntryID\n",
    "    entry_id = 'A0A009IHW8'\n",
    "    encoded_matrix = encoded_matrices[entry_id]\n",
    "\n",
    "    # Example usage: Decode a specific term for the EntryID\n",
    "    term_id = 42  # Example term ID\n",
    "    term = unique_terms[term_id]\n",
    "    decoded_term = term\n",
    "\n",
    "    # Print the encoded matrix for the EntryID\n",
    "    print(encoded_matrix)\n",
    "\n",
    "    # Print the decoded term for the EntryID\n",
    "    print(decoded_term)\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Load the encoded_matrices dictionary from file\n",
    "    with open('/kaggle/input/modelcafa5/encoded_matrices.pkl', 'rb') as file:\n",
    "        encoded_matrices = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad162978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T13:23:59.783682Z",
     "iopub.status.busy": "2023-07-06T13:23:59.782592Z",
     "iopub.status.idle": "2023-07-06T13:23:59.797461Z",
     "shell.execute_reply": "2023-07-06T13:23:59.796439Z"
    },
    "papermill": {
     "duration": 0.026591,
     "end_time": "2023-07-06T13:23:59.800265",
     "exception": false,
     "start_time": "2023-07-06T13:23:59.773674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from Bio import SeqIO\n",
    "\n",
    "def get_fasta_1(fasta_file):\n",
    "    # Create empty lists to store the sequences and protein IDs\n",
    "    sequences = []\n",
    "    protein_ids = []\n",
    "    max_length = 60\n",
    "\n",
    "    # Open and read the .fasta file\n",
    "    with open(fasta_file, \"r\") as handle:\n",
    "        # Use the SeqIO.parse() function to parse the .fasta file\n",
    "        # SeqIO.parse() returns an iterator over the sequences in the file\n",
    "        records = SeqIO.parse(handle, \"fasta\")\n",
    "\n",
    "        # Iterate over the sequences\n",
    "        for record in records:\n",
    "            # Access the RegisterID and sequence\n",
    "            register_id = record.id\n",
    "            sequence = str(record.seq)  # Convert sequence to string if needed\n",
    "\n",
    "            # Add the sequence and protein ID to the lists\n",
    "            sequences.append(sequence[:max_length])  # Only take the first 20 characters\n",
    "            protein_ids.append(register_id)\n",
    "\n",
    "    # Create a set to store unique amino acids, excluding padding character '-'\n",
    "    amino_acids = set()\n",
    "    \n",
    "    # Iterate over the sequences to determine unique amino acids\n",
    "    for sequence in sequences:\n",
    "        amino_acids.update(sequence)\n",
    "\n",
    "    # Determine the maximum sequence length and the number of unique amino acids\n",
    "    num_amino_acids = len(amino_acids)\n",
    "\n",
    "    # Create a list to store the flattened sparse matrices\n",
    "    sparse_matrices = []\n",
    "    \n",
    "    # Iterate over the sequences\n",
    "    for sequence in sequences:\n",
    "        # Truncate or pad the sequence to a length of 20 amino acids\n",
    "        truncated_sequence = sequence.ljust(max_length, '-')\n",
    "\n",
    "        # Encode the sequence as a sparse matrix\n",
    "        row_indices = []\n",
    "        col_indices = []\n",
    "        data = []\n",
    "        for i, amino_acid in enumerate(truncated_sequence):\n",
    "            if amino_acid != '-':\n",
    "                amino_acid_index = list(amino_acids).index(amino_acid)\n",
    "                row_indices.append(i)\n",
    "                col_indices.append(amino_acid_index)\n",
    "                data.append(1)\n",
    "\n",
    "        # Create the sparse matrix\n",
    "        dataset = csr_matrix((data, (row_indices, col_indices)), shape=(max_length, num_amino_acids))\n",
    "        \n",
    "        # Append the sparse matrix to the list\n",
    "        sparse_matrices.append(dataset.toarray().flatten())\n",
    "\n",
    "    # Create a pandas DataFrame from the list of flattened sparse matrices\n",
    "    column_names = [f\"Position_{i+1}_{aa}\" for i in range(max_length) for aa in amino_acids]\n",
    "    df = pd.DataFrame(sparse_matrices, columns=column_names)\n",
    "\n",
    "    # Add the protein IDs as a column in the DataFrame\n",
    "    df['EntryID'] = protein_ids\n",
    "\n",
    "    # Return the pandas DataFrame\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6442ef63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T13:23:59.818191Z",
     "iopub.status.busy": "2023-07-06T13:23:59.817747Z",
     "iopub.status.idle": "2023-07-06T13:23:59.827391Z",
     "shell.execute_reply": "2023-07-06T13:23:59.826032Z"
    },
    "papermill": {
     "duration": 0.021638,
     "end_time": "2023-07-06T13:23:59.830110",
     "exception": false,
     "start_time": "2023-07-06T13:23:59.808472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fasta_2(data1,fasta_file):\n",
    "    # Create an empty list to store the encoded data\n",
    "    encoded_data = []\n",
    "\n",
    "    # Open and read the .fasta file\n",
    "    with open(fasta_file, \"r\") as handle:\n",
    "        # Use the SeqIO.parse() function to parse the .fasta file\n",
    "        # SeqIO.parse() returns an iterator over the sequences in the file\n",
    "        records = SeqIO.parse(handle, \"fasta\")\n",
    "\n",
    "        # Iterate over the sequences\n",
    "        for record in records:\n",
    "            # Access the RegisterID and sequence\n",
    "            register_id = record.id\n",
    "            sequence = str(record.seq)  # Convert sequence to string if needed\n",
    "\n",
    "            # Create a Counter object for the sequence\n",
    "            sequence_counts = Counter(sequence)\n",
    "\n",
    "            # Duplicate the sequence_counts columns\n",
    "            duplicated_counts = {k + \"_copy\": v for k, v in sequence_counts.items()}\n",
    "\n",
    "            # Append the RegisterID, sequence_counts, and duplicated_counts to the encoded data\n",
    "            encoded_data.append({\"EntryID\": register_id, **sequence_counts, **duplicated_counts})\n",
    "\n",
    "    # Create a pandas DataFrame from the encoded data\n",
    "    data = pd.DataFrame(encoded_data)\n",
    "\n",
    "    # Print the resulting DataFrame\n",
    "    data = data.fillna(0)\n",
    "    \n",
    "    # Merge the two DataFrames on the 'EntryID' column\n",
    "    merged_df = pd.merge(data1, data, on='EntryID')\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d375cf60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T13:23:59.847909Z",
     "iopub.status.busy": "2023-07-06T13:23:59.847329Z",
     "iopub.status.idle": "2023-07-06T13:42:51.105259Z",
     "shell.execute_reply": "2023-07-06T13:42:51.104013Z"
    },
    "papermill": {
     "duration": 1131.279644,
     "end_time": "2023-07-06T13:42:51.117366",
     "exception": false,
     "start_time": "2023-07-06T13:23:59.837722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position_1_T</th>\n",
       "      <th>Position_1_R</th>\n",
       "      <th>Position_1_Q</th>\n",
       "      <th>Position_1_G</th>\n",
       "      <th>Position_1_M</th>\n",
       "      <th>Position_1_K</th>\n",
       "      <th>Position_1_P</th>\n",
       "      <th>Position_1_L</th>\n",
       "      <th>Position_1_I</th>\n",
       "      <th>Position_1_V</th>\n",
       "      <th>...</th>\n",
       "      <th>U</th>\n",
       "      <th>U_copy</th>\n",
       "      <th>O</th>\n",
       "      <th>O_copy</th>\n",
       "      <th>X</th>\n",
       "      <th>X_copy</th>\n",
       "      <th>B</th>\n",
       "      <th>B_copy</th>\n",
       "      <th>Z</th>\n",
       "      <th>Z_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142241</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142242</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142243</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142244</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142245</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142246 rows × 1371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Position_1_T  Position_1_R  Position_1_Q  Position_1_G  Position_1_M  \\\n",
       "0                  0             0             0             0             1   \n",
       "1                  0             0             0             0             1   \n",
       "2                  0             0             0             0             1   \n",
       "3                  0             0             0             0             1   \n",
       "4                  0             0             0             0             1   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "142241             0             0             0             0             1   \n",
       "142242             0             0             0             0             1   \n",
       "142243             0             0             0             0             1   \n",
       "142244             0             0             0             0             1   \n",
       "142245             0             0             0             0             0   \n",
       "\n",
       "        Position_1_K  Position_1_P  Position_1_L  Position_1_I  Position_1_V  \\\n",
       "0                  0             0             0             0             0   \n",
       "1                  0             0             0             0             0   \n",
       "2                  0             0             0             0             0   \n",
       "3                  0             0             0             0             0   \n",
       "4                  0             0             0             0             0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "142241             0             0             0             0             0   \n",
       "142242             0             0             0             0             0   \n",
       "142243             0             0             0             0             0   \n",
       "142244             0             0             0             0             0   \n",
       "142245             0             0             0             0             0   \n",
       "\n",
       "        ...    U  U_copy    O  O_copy    X  X_copy    B  B_copy    Z  Z_copy  \n",
       "0       ...  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "1       ...  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "2       ...  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "3       ...  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "4       ...  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "...     ...  ...     ...  ...     ...  ...     ...  ...     ...  ...     ...  \n",
       "142241  ...  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "142242  ...  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "142243  ...  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "142244  ...  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "142245  ...  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "\n",
       "[142246 rows x 1371 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the .fasta file\n",
    "fasta_file = \"/kaggle/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta\"\n",
    "\n",
    "data1 = get_fasta_1(fasta_file)\n",
    "data = get_fasta_2(data1,fasta_file)\n",
    "    \n",
    "data= data.fillna(0)\n",
    "data.to_csv('data.csv', index=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c10e87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T13:42:51.135527Z",
     "iopub.status.busy": "2023-07-06T13:42:51.135128Z",
     "iopub.status.idle": "2023-07-06T13:42:51.175379Z",
     "shell.execute_reply": "2023-07-06T13:42:51.173613Z"
    },
    "papermill": {
     "duration": 0.052648,
     "end_time": "2023-07-06T13:42:51.178224",
     "exception": false,
     "start_time": "2023-07-06T13:42:51.125576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142246 142246\n"
     ]
    }
   ],
   "source": [
    "print(len(data['EntryID']),len(data['EntryID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa708eea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T13:42:51.197206Z",
     "iopub.status.busy": "2023-07-06T13:42:51.196757Z",
     "iopub.status.idle": "2023-07-06T18:14:20.830984Z",
     "shell.execute_reply": "2023-07-06T18:14:20.828672Z"
    },
    "papermill": {
     "duration": 16289.647435,
     "end_time": "2023-07-06T18:14:20.834159",
     "exception": false,
     "start_time": "2023-07-06T13:42:51.186724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after 142246 iterations\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "['GO:0008150']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "if not load_model_quim:\n",
    "    \n",
    "    # Define the model architecture\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Reshape((-1, 1), input_shape=(len(data.columns)-1,)))  # Reshape input to (num_features, 1)\n",
    "    model.add(layers.Conv1D(64, kernel_size=3, activation='relu'))  # Convolutional layer\n",
    "    model.add(layers.Conv1D(32, kernel_size=3, activation='relu'))  # Convolutional layer\n",
    "    model.add(layers.Flatten())  # Flatten the output\n",
    "    model.add(layers.Dense(128, activation='relu'))  # Hidden layer\n",
    "    model.add(layers.Dense(64, activation='relu'))  # Hidden layer\n",
    "    model.add(layers.Dense(31466, activation='sigmoid'))  # Output layer\n",
    "\n",
    "    # Set the learning rate\n",
    "    learning_rate = 0.0005\n",
    "\n",
    "    # Create a custom optimizer with the desired learning rate\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model with the custom optimizer\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "\n",
    "    i = 0\n",
    "    # Iterate over each EntryID and update the model\n",
    "    for entry_id in data['EntryID'].unique():\n",
    "        # Get the encoded matrix for the current EntryID\n",
    "        encoded_matrix = encoded_matrices[entry_id]\n",
    "\n",
    "        # Prepare the input features (data) for training\n",
    "        input_features = data.loc[data['EntryID'] == entry_id].drop(columns='EntryID').values\n",
    "\n",
    "        # Update the model with new data for the current EntryID\n",
    "        model.train_on_batch(input_features, encoded_matrix.toarray())\n",
    "\n",
    "        print(i, entry_id, end=\"\\r\")\n",
    "        i += 1\n",
    "\n",
    "    # Save the model\n",
    "    model.save('model_new_2.h5')\n",
    "    print(\"Model saved after\", i, \"iterations\")\n",
    "    \n",
    "else:\n",
    "\n",
    "    # Load the model\n",
    "    model = load_model('/kaggle/input/modelcafa5/model_new_2.h5')\n",
    "    \n",
    "# Example usage: Make predictions for a specific EntryID\n",
    "entry_id = 'A0A009IHW8'\n",
    "input_features = data.loc[data['EntryID'] == entry_id].drop(columns='EntryID').values\n",
    "prediction = model.predict(input_features)\n",
    "\n",
    "# Example usage: Decode the predicted matrix for the EntryID\n",
    "decoded_prediction = prediction.argmax(axis=1)\n",
    "\n",
    "# Decode the predicted terms using the term_to_id dictionary\n",
    "decoded_terms = [unique_terms[term_id] for term_id in decoded_prediction]\n",
    "\n",
    "# Print the decoded terms\n",
    "print(decoded_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a14a85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T18:14:31.475018Z",
     "iopub.status.busy": "2023-07-06T18:14:31.474081Z",
     "iopub.status.idle": "2023-07-06T18:14:31.485315Z",
     "shell.execute_reply": "2023-07-06T18:14:31.483856Z"
    },
    "papermill": {
     "duration": 5.317186,
     "end_time": "2023-07-06T18:14:31.488190",
     "exception": false,
     "start_time": "2023-07-06T18:14:26.171004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7268150e-01, 1.2313638e-02, 1.7045165e-04, ..., 4.3388412e-05,\n",
       "        4.3407203e-05, 4.3677519e-05]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3f8584a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T18:14:42.249334Z",
     "iopub.status.busy": "2023-07-06T18:14:42.248564Z",
     "iopub.status.idle": "2023-07-06T18:14:42.394813Z",
     "shell.execute_reply": "2023-07-06T18:14:42.393367Z"
    },
    "papermill": {
     "duration": 5.459835,
     "end_time": "2023-07-06T18:14:42.397742",
     "exception": false,
     "start_time": "2023-07-06T18:14:36.937907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GO:0008150', 'GO:0005575', 'GO:0110165', 'GO:0005622', 'GO:0003674', 'GO:0043226', 'GO:0009987', 'GO:0043229', 'GO:0043227', 'GO:0043231', 'GO:0005488', 'GO:0005737', 'GO:0005515', 'GO:0005634', 'GO:0065007', 'GO:0050789', 'GO:0032502', 'GO:0048856', 'GO:0032501', 'GO:0050794', 'GO:0008152', 'GO:0050896', 'GO:0071704', 'GO:0044237', 'GO:0044238', 'GO:0043170', 'GO:0006807', 'GO:0071840', 'GO:0007275', 'GO:0016043', 'GO:0019222', 'GO:0006950', 'GO:0043228', 'GO:0043232', 'GO:0060255', 'GO:0003824', 'GO:0031981', 'GO:0031974', 'GO:0070013', 'GO:0043233', 'GO:0006996', 'GO:0010468', 'GO:0032991', 'GO:0051716', 'GO:1901363', 'GO:0048869', 'GO:0097159', 'GO:0031323', 'GO:0000003', 'GO:0080090', 'GO:0030154', 'GO:0006725', 'GO:0048731', 'GO:1901360', 'GO:0005829', 'GO:0051171', 'GO:0034641', 'GO:0003676', 'GO:0046483', 'GO:0048513', 'GO:0005654', 'GO:0071944', 'GO:0016020', 'GO:0048468', 'GO:0006139', 'GO:0048519', 'GO:0090304', 'GO:0048518', 'GO:0033554', 'GO:0022414', 'GO:0019219', 'GO:0051179', 'GO:0009653', 'GO:0009889', 'GO:0012505', 'GO:0007049', 'GO:0031326', 'GO:0019953', 'GO:0022402', 'GO:0010556', 'GO:0051252', 'GO:1901564', 'GO:0009605', 'GO:0044260', 'GO:0044085', 'GO:0030447', 'GO:0032504', 'GO:0048523', 'GO:0003006', 'GO:0016740', 'GO:0040007', 'GO:0140096', 'GO:0005886', 'GO:0019538', 'GO:0048522', 'GO:0051234', 'GO:0022412', 'GO:0009888', 'GO:1903506', 'GO:0007276', 'GO:0022607', 'GO:0006355', 'GO:2001141', 'GO:0007154', 'GO:0005694', 'GO:0042221', 'GO:0048609', 'GO:0051641', 'GO:0048583', 'GO:0005856', 'GO:0006810', 'GO:0016070', 'GO:0044182', 'GO:0009607', 'GO:0003677', 'GO:0009790', 'GO:0007399', 'GO:0007010', 'GO:0043412', 'GO:0009892', 'GO:0010604', 'GO:0009893', 'GO:0015630', 'GO:1902494', 'GO:0000278', 'GO:0140513', 'GO:0044419', 'GO:0010605', 'GO:0060429', 'GO:0051649', 'GO:0099080', 'GO:0010467', 'GO:0036211', 'GO:0009791', 'GO:0016772', 'GO:0051726', 'GO:1903047', 'GO:0006796', 'GO:0006793', 'GO:0050793', 'GO:0051128', 'GO:0009058', 'GO:0043565', 'GO:1901576', 'GO:0003723', 'GO:0044249', 'GO:0007281', 'GO:0051173', 'GO:0031325', 'GO:0030054', 'GO:0009887', 'GO:0031982', 'GO:0023052', 'GO:0009056', 'GO:0070887', 'GO:0000280', 'GO:0046907', 'GO:0051707', 'GO:0048285', 'GO:0043207', 'GO:0016787', 'GO:0033036', 'GO:0031324', 'GO:0005815', 'GO:0009628', 'GO:0016773', 'GO:0044248', 'GO:0070925', 'GO:0042995', 'GO:0006259', 'GO:0048646', 'GO:0120025', 'GO:0097708', 'GO:0065008', 'GO:0031410', 'GO:0007292', 'GO:0051239', 'GO:0007423', 'GO:0051172', 'GO:0022008', 'GO:0005813', 'GO:0045935', 'GO:0031975', 'GO:0051254', 'GO:0016301', 'GO:0007165', 'GO:0051276', 'GO:0140535', 'GO:0007017', 'GO:0009536', 'GO:0006952', 'GO:0048729', 'GO:0009966', 'GO:0042594', 'GO:0030030', 'GO:0009991', 'GO:0003690', 'GO:0048699', 'GO:0002009', 'GO:0006974', 'GO:0009891', 'GO:0120036', 'GO:0031667', 'GO:0003729', 'GO:0002376', 'GO:0010564', 'GO:0098542', 'GO:0030029', 'GO:0048598', 'GO:1990837', 'GO:0023051', 'GO:0048477', 'GO:0031328', 'GO:0006357', 'GO:0010646', 'GO:0070727', 'GO:0010557', 'GO:0051321', 'GO:0031967', 'GO:0000785', 'GO:0030036', 'GO:0010629', 'GO:0030182', 'GO:0007059', 'GO:1902680', 'GO:0033043', 'GO:0045893', 'GO:1903046', 'GO:0051246', 'GO:1903508', 'GO:0005794', 'GO:0009059', 'GO:0048880', 'GO:0000976', 'GO:0005730', 'GO:0008104', 'GO:0004672', 'GO:0001067', 'GO:0140110', 'GO:1901575', 'GO:0098813', 'GO:0031668', 'GO:0071496', 'GO:0048584', 'GO:0006396', 'GO:1990234', 'GO:0019899', 'GO:0007444', 'GO:0010033', 'GO:0000226', 'GO:0000793', 'GO:0040008', 'GO:0001654', 'GO:0150063', 'GO:0031090', 'GO:0048232', 'GO:0007389', 'GO:0031327', 'GO:0031669', 'GO:0009890', 'GO:0016192', 'GO:0016071', 'GO:0016788', 'GO:0009267', 'GO:0044271', 'GO:0099512', 'GO:0016310', 'GO:0048870', 'GO:0003002', 'GO:0048666', 'GO:0036180', 'GO:0009057', 'GO:0140013', 'GO:0010558', 'GO:0099081', 'GO:0003008', 'GO:0042592', 'GO:0140694', 'GO:0140640', 'GO:0098687', 'GO:0051640', 'GO:0051301', 'GO:0007552', 'GO:0003700', 'GO:0002165', 'GO:0098590', 'GO:0005635', 'GO:0006468', 'GO:0097435', 'GO:0048707', 'GO:0044265', 'GO:0035556', 'GO:0051703', 'GO:0009886', 'GO:0048569', 'GO:0080134', 'GO:0032989', 'GO:0000775', 'GO:1901700', 'GO:0009792', 'GO:0005739', 'GO:0035295', 'GO:0007283', 'GO:1902531', 'GO:0045202', 'GO:0098772', 'GO:0072359', 'GO:0045177', 'GO:0010608', 'GO:0007417', 'GO:0004674', 'GO:0044281', 'GO:0030097', 'GO:0005819', 'GO:0061061', 'GO:0048585', 'GO:0000902', 'GO:0006281', 'GO:0032879', 'GO:0070161', 'GO:0005783', 'GO:0030234', 'GO:1901362', 'GO:0030855', 'GO:0043933', 'GO:0042802', 'GO:1901566', 'GO:0071702', 'GO:0043167', 'GO:0019438', 'GO:0043005', 'GO:0035220', 'GO:0016604', 'GO:0045934', 'GO:0005938', 'GO:0030031', 'GO:0007610', 'GO:0035239', 'GO:0042578', 'GO:0016477', 'GO:0034660', 'GO:0050790', 'GO:0048589', 'GO:0007560', 'GO:0071310', 'GO:0051493', 'GO:0065009', 'GO:0036170', 'GO:0045944', 'GO:2000026', 'GO:0009617', 'GO:0120031', 'GO:0009266', 'GO:0032101', 'GO:0071705', 'GO:0005911', 'GO:0002831', 'GO:0002682', 'GO:0048563', 'GO:0002064', 'GO:0061458', 'GO:0034248', 'GO:0042692', 'GO:0005929', 'GO:0031329', 'GO:1990904', 'GO:0009894', 'GO:0045595', 'GO:0000904', 'GO:0051146', 'GO:0099568', 'GO:0010927', 'GO:0043656', 'GO:0005768', 'GO:0051248', 'GO:0010256', 'GO:0033646', 'GO:0046700', 'GO:0051656', 'GO:0010941', 'GO:0031175', 'GO:0090066', 'GO:0030430', 'GO:0018130', 'GO:0098588', 'GO:0002164', 'GO:0048568', 'GO:0065003', 'GO:0044782', 'GO:1901361', 'GO:0045132', 'GO:0051253', 'GO:0007507', 'GO:2000112', 'GO:0005576', 'GO:0140098', 'GO:0044403', 'GO:1901701', 'GO:0140677', 'GO:0048608', 'GO:0043292', 'GO:0019439', 'GO:0007346', 'GO:0000779', 'GO:0045184', 'GO:0006417', 'GO:0043168', 'GO:0006397', 'GO:0060271', 'GO:0051049', 'GO:0035770', 'GO:0005667', 'GO:0048592', 'GO:0044087', 'GO:0031032', 'GO:0006979', 'GO:0055001', 'GO:0034655', 'GO:0008092', 'GO:0040011', 'GO:0015629', 'GO:0010628', 'GO:0008283', 'GO:0042742', 'GO:0036464', 'GO:0009968', 'GO:0035114', 'GO:0043657', 'GO:0051701', 'GO:0018995', 'GO:1903507', 'GO:1902679', 'GO:0045892', 'GO:0051129', 'GO:0048515', 'GO:0043067', 'GO:0033643', 'GO:0035120', 'GO:0007163', 'GO:2000241', 'GO:0005773', 'GO:0090596', 'GO:0000910', 'GO:0051093', 'GO:0048737', 'GO:0006955', 'GO:1901987', 'GO:0034654', 'GO:0048736', 'GO:0030016', 'GO:0034645', 'GO:0044270', 'GO:0060322', 'GO:0032970', 'GO:0006897', 'GO:0060627', 'GO:0010570', 'GO:0000776', 'GO:0032956', 'GO:0050877', 'GO:0007420', 'GO:0045786', 'GO:0016791', 'GO:0048749', 'GO:0015031', 'GO:0033655', 'GO:0023057', 'GO:0008380', 'GO:0019220', 'GO:1900428', 'GO:0051174', 'GO:0009967', 'GO:0032153', 'GO:0140014', 'GO:0010648', 'GO:0030707', 'GO:0008289', 'GO:0031984', 'GO:0030017', 'GO:0023056', 'GO:0061982', 'GO:0042127', 'GO:0010647', 'GO:0007267', 'GO:0034249', 'GO:0030239', 'GO:0001667', 'GO:0071214', 'GO:0104004', 'GO:0007286', 'GO:0006325', 'GO:0034330', 'GO:0048732', 'GO:0042330', 'GO:0006310', 'GO:0051241', 'GO:0061919', 'GO:0006629', 'GO:0006401', 'GO:0034470', 'GO:0006914', 'GO:0051336', 'GO:1901698', 'GO:0042981', 'GO:0009314', 'GO:0008340']\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.01  # Probability threshold\n",
    "\n",
    "# Apply thresholding to the prediction probabilities\n",
    "thresholded_prediction = prediction.copy()\n",
    "thresholded_prediction[thresholded_prediction < threshold] = 0\n",
    "\n",
    "# Get the indices of the terms with probabilities above the threshold\n",
    "term_indices = thresholded_prediction.argsort(axis=1)[:, ::-1]\n",
    "\n",
    "# Retrieve the terms corresponding to the indices\n",
    "predicted_terms = [[unique_terms[idx] for idx in indices if thresholded_prediction[i, idx] > 0] for i, indices in enumerate(term_indices)]\n",
    "\n",
    "# Print the predicted terms for each sample\n",
    "for terms in predicted_terms:\n",
    "    print(terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03be85ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T18:14:53.086773Z",
     "iopub.status.busy": "2023-07-06T18:14:53.085470Z",
     "iopub.status.idle": "2023-07-06T18:14:54.090329Z",
     "shell.execute_reply": "2023-07-06T18:14:54.089464Z"
    },
    "papermill": {
     "duration": 6.392554,
     "end_time": "2023-07-06T18:14:54.092695",
     "exception": false,
     "start_time": "2023-07-06T18:14:47.700141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GO:0003953',\n",
       " 'GO:0006163',\n",
       " 'GO:0006195',\n",
       " 'GO:0006753',\n",
       " 'GO:0009117',\n",
       " 'GO:0009166',\n",
       " 'GO:0016798',\n",
       " 'GO:0016799',\n",
       " 'GO:0019362',\n",
       " 'GO:0019364',\n",
       " 'GO:0019637',\n",
       " 'GO:0019674',\n",
       " 'GO:0019677',\n",
       " 'GO:0046434',\n",
       " 'GO:0046496',\n",
       " 'GO:0055086',\n",
       " 'GO:0072521',\n",
       " 'GO:0072523',\n",
       " 'GO:0072524',\n",
       " 'GO:0072526',\n",
       " 'GO:1901292',\n",
       " 'GO:1901565'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_terms[train_terms['EntryID'] == 'A0A009IHW8']['term']) - set(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8431df62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T18:15:04.667606Z",
     "iopub.status.busy": "2023-07-06T18:15:04.666721Z",
     "iopub.status.idle": "2023-07-06T18:35:57.384806Z",
     "shell.execute_reply": "2023-07-06T18:35:57.381114Z"
    },
    "papermill": {
     "duration": 1258.183403,
     "end_time": "2023-07-06T18:35:57.391074",
     "exception": false,
     "start_time": "2023-07-06T18:14:59.207671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_file = '/kaggle/input/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta'\n",
    "testA = get_fasta_1(test_file)\n",
    "test1 = get_fasta_2(testA,test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eb9e7c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T18:36:21.908797Z",
     "iopub.status.busy": "2023-07-06T18:36:21.906587Z",
     "iopub.status.idle": "2023-07-06T18:36:29.901608Z",
     "shell.execute_reply": "2023-07-06T18:36:29.900232Z"
    },
    "papermill": {
     "duration": 21.995553,
     "end_time": "2023-07-06T18:36:29.905872",
     "exception": false,
     "start_time": "2023-07-06T18:36:07.910319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position_1_T</th>\n",
       "      <th>Position_1_R</th>\n",
       "      <th>Position_1_Q</th>\n",
       "      <th>Position_1_G</th>\n",
       "      <th>Position_1_M</th>\n",
       "      <th>Position_1_K</th>\n",
       "      <th>Position_1_P</th>\n",
       "      <th>Position_1_L</th>\n",
       "      <th>Position_1_I</th>\n",
       "      <th>Position_1_V</th>\n",
       "      <th>...</th>\n",
       "      <th>U</th>\n",
       "      <th>U_copy</th>\n",
       "      <th>O</th>\n",
       "      <th>O_copy</th>\n",
       "      <th>X</th>\n",
       "      <th>X_copy</th>\n",
       "      <th>B</th>\n",
       "      <th>B_copy</th>\n",
       "      <th>Z</th>\n",
       "      <th>Z_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141862</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141863</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141864</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141865</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141866</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141867 rows × 1371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Position_1_T  Position_1_R  Position_1_Q  Position_1_G  Position_1_M  \\\n",
       "0                  0             0             0             0             1   \n",
       "1                  0             0             0             0             1   \n",
       "2                  0             0             0             0             1   \n",
       "3                  0             0             0             0             1   \n",
       "4                  0             0             0             0             1   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "141862             0             0             0             1             0   \n",
       "141863             0             1             0             0             0   \n",
       "141864             0             0             0             1             0   \n",
       "141865             0             0             0             1             0   \n",
       "141866             0             0             0             1             0   \n",
       "\n",
       "        Position_1_K  Position_1_P  Position_1_L  Position_1_I  Position_1_V  \\\n",
       "0                  0             0             0             0             0   \n",
       "1                  0             0             0             0             0   \n",
       "2                  0             0             0             0             0   \n",
       "3                  0             0             0             0             0   \n",
       "4                  0             0             0             0             0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "141862             0             0             0             0             0   \n",
       "141863             0             0             0             0             0   \n",
       "141864             0             0             0             0             0   \n",
       "141865             0             0             0             0             0   \n",
       "141866             0             0             0             0             0   \n",
       "\n",
       "        ...    U  U_copy  O  O_copy    X  X_copy    B  B_copy    Z  Z_copy  \n",
       "0       ...  0.0     0.0  0       0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "1       ...  0.0     0.0  0       0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "2       ...  0.0     0.0  0       0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "3       ...  0.0     0.0  0       0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "4       ...  0.0     0.0  0       0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "...     ...  ...     ... ..     ...  ...     ...  ...     ...  ...     ...  \n",
       "141862  ...  0.0     0.0  0       0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "141863  ...  0.0     0.0  0       0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "141864  ...  0.0     0.0  0       0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "141865  ...  0.0     0.0  0       0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "141866  ...  0.0     0.0  0       0  0.0     0.0  0.0     0.0  0.0     0.0  \n",
       "\n",
       "[141867 rows x 1371 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any columns in data are missing in test\n",
    "missing_columns = list(set(data.columns) - set(test1.columns))\n",
    "\n",
    "# Create a DataFrame with missing columns and fill with 0\n",
    "missing_df = pd.DataFrame(0, index=test1.index, columns=missing_columns)\n",
    "\n",
    "# Concatenate missing_df with test1\n",
    "test1 = pd.concat([test1, missing_df], axis=1)\n",
    "\n",
    "# Remove additional columns from test1\n",
    "extra_columns = list(set(test1.columns) - set(data.columns))\n",
    "test1 = test1.drop(columns=extra_columns)\n",
    "\n",
    "# Reorder columns in test1 to match the order in data\n",
    "test = test1[data.columns]\n",
    "\n",
    "# Print the updated DataFrame\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71fd955f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T18:36:40.585745Z",
     "iopub.status.busy": "2023-07-06T18:36:40.585359Z",
     "iopub.status.idle": "2023-07-06T18:44:38.714229Z",
     "shell.execute_reply": "2023-07-06T18:44:38.713028Z"
    },
    "papermill": {
     "duration": 489.000338,
     "end_time": "2023-07-06T18:44:44.275830",
     "exception": false,
     "start_time": "2023-07-06T18:36:35.275492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length protein ids: 141867\n",
      "total terms: 53007593 total proteins: 141867\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein Id</th>\n",
       "      <th>GO Term Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9CQV8</td>\n",
       "      <td>GO:0008152</td>\n",
       "      <td>0.118578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9CQV8</td>\n",
       "      <td>GO:0044237</td>\n",
       "      <td>0.103990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q9CQV8</td>\n",
       "      <td>GO:1901360</td>\n",
       "      <td>0.063164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9CQV8</td>\n",
       "      <td>GO:0008150</td>\n",
       "      <td>0.601585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q9CQV8</td>\n",
       "      <td>GO:1901564</td>\n",
       "      <td>0.045255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53007588</th>\n",
       "      <td>A0A3G2FQK2</td>\n",
       "      <td>GO:0048018</td>\n",
       "      <td>0.018682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53007589</th>\n",
       "      <td>A0A3G2FQK2</td>\n",
       "      <td>GO:0030545</td>\n",
       "      <td>0.018369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53007590</th>\n",
       "      <td>A0A3G2FQK2</td>\n",
       "      <td>GO:0030546</td>\n",
       "      <td>0.018605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53007591</th>\n",
       "      <td>A0A3G2FQK2</td>\n",
       "      <td>GO:0003729</td>\n",
       "      <td>0.016038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53007592</th>\n",
       "      <td>A0A3G2FQK2</td>\n",
       "      <td>GO:0005198</td>\n",
       "      <td>0.013437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53007593 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Protein Id  GO Term Id  Prediction\n",
       "0             Q9CQV8  GO:0008152    0.118578\n",
       "1             Q9CQV8  GO:0044237    0.103990\n",
       "2             Q9CQV8  GO:1901360    0.063164\n",
       "3             Q9CQV8  GO:0008150    0.601585\n",
       "4             Q9CQV8  GO:1901564    0.045255\n",
       "...              ...         ...         ...\n",
       "53007588  A0A3G2FQK2  GO:0048018    0.018682\n",
       "53007589  A0A3G2FQK2  GO:0030545    0.018369\n",
       "53007590  A0A3G2FQK2  GO:0030546    0.018605\n",
       "53007591  A0A3G2FQK2  GO:0003729    0.016038\n",
       "53007592  A0A3G2FQK2  GO:0005198    0.013437\n",
       "\n",
       "[53007593 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the protein IDs\n",
    "protein_ids = test['EntryID']\n",
    "print(\"length protein ids:\", len(protein_ids))\n",
    "\n",
    "# Create an empty list to store data for submission\n",
    "submission_data = []\n",
    "\n",
    "batch_size = 1000  # Adjust the batch size as per your memory constraints\n",
    "\n",
    "total_terms = 0\n",
    "proteins = 0\n",
    "\n",
    "# Process the dataset in batches\n",
    "for start_index in range(0, len(protein_ids), batch_size):\n",
    "    end_index = start_index + batch_size\n",
    "    \n",
    "    # Get the protein IDs and input features for the current batch\n",
    "    batch_protein_ids = protein_ids[start_index:end_index]\n",
    "    batch_input_features = test.loc[test['EntryID'].isin(batch_protein_ids)].drop(columns='EntryID').values\n",
    "    \n",
    "    # Make predictions for the current batch using the trained model\n",
    "    batch_predictions = model.predict(batch_input_features, verbose=0)\n",
    "    \n",
    "    # Iterate over the proteins in the batch\n",
    "    for i, protein_id in enumerate(batch_protein_ids):\n",
    "        # Get the predictions and input features for the current protein\n",
    "        protein_predictions = batch_predictions[i]\n",
    "        protein_input_features = batch_input_features[i]\n",
    "        \n",
    "        # Apply thresholding to the predictions\n",
    "        thresholded_predictions = protein_predictions > threshold\n",
    "        \n",
    "        # Retrieve the indices of the terms with predictions above the threshold\n",
    "        term_indices = thresholded_predictions.nonzero()[0]\n",
    "        \n",
    "        # Retrieve the terms corresponding to the indices\n",
    "        predicted_terms = [unique_terms[idx] for idx in term_indices]\n",
    "        \n",
    "        total_terms += len(term_indices)\n",
    "        proteins += 1\n",
    "        print('total terms:', total_terms, 'total proteins:', proteins, end='\\r')\n",
    "        \n",
    "        # Generate the GO term IDs based on the protein ID\n",
    "        go_term_ids = [f'{term}' for term in predicted_terms]\n",
    "        \n",
    "        # Append the protein ID, GO term IDs, and predictions to the submission data\n",
    "        submission_data.extend(zip([protein_id] * len(go_term_ids), go_term_ids, protein_predictions[term_indices]))\n",
    "        \n",
    "    # Clear variables to release memory\n",
    "    del batch_protein_ids, batch_input_features, batch_predictions\n",
    "\n",
    "# Create the submission DataFrame\n",
    "df_submission = pd.DataFrame(submission_data, columns=['Protein Id', 'GO Term Id', 'Prediction'])\n",
    "\n",
    "# Save the submission DataFrame to a TSV file\n",
    "df_submission.to_csv(\"submission.tsv\", header=False, index=False, sep=\"\\t\")\n",
    "df_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19293.760804,
   "end_time": "2023-07-06T18:44:53.649645",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-06T13:23:19.888841",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
